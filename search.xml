<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>「消息队列」 如何保证消息队列的高可用？</title>
      <link href="/mq-knowledge/how-to-ensure-high-availability-of-message-queues.html"/>
      <url>/mq-knowledge/how-to-ensure-high-availability-of-message-queues.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息队列的高可用？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>如果有人问到你 MQ 的知识，<strong>高可用是必问的</strong>。<a href="/docs/high-concurrency/why-mq.md">上一讲</a>提到，MQ 会导致<strong>系统可用性降低</strong>。所以只要你用了 MQ，接下来问的一些要点肯定就是围绕着 MQ 的那些缺点怎么来解决了。</p><p>要是你傻乎乎的就干用了一个 MQ，各种问题从来没考虑过，那你就杯具了，面试官对你的印象就是，只会简单使用一些技术，没任何思考，马上对你的印象就不太好了。这样的同学招进来要是做个 20k 薪资以内的普通小弟还凑合，要是做薪资 20k+ 的高工，那就惨了，让你设计个系统，里面肯定一堆坑，出了事故公司受损失，团队一起背锅。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个问题这么问是很好的，因为不能问你 Kafka 的高可用性怎么保证？ActiveMQ 的高可用性怎么保证？一个面试官要是这么问就显得很没水平，人家可能用的就是 RabbitMQ，没用过 Kafka，你上来问人家 Kafka 干什么？这不是摆明了刁难人么。</p><p>所以有水平的面试官，问的是 MQ 的高可用性怎么保证？这样就是你用过哪个 MQ，你就说说你对那个 MQ 的高可用性的理解。</p><h3 id="RabbitMQ-的高可用性"><a href="#RabbitMQ-的高可用性" class="headerlink" title="RabbitMQ 的高可用性"></a>RabbitMQ 的高可用性</h3><p>RabbitMQ 是比较有代表性的，因为是<strong>基于主从</strong>（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。</p><p>RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</p><h4 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h4><p>单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的😄，没人生产用单机模式。</p><h4 id="普通集群模式（无高可用性）"><a href="#普通集群模式（无高可用性）" class="headerlink" title="普通集群模式（无高可用性）"></a>普通集群模式（无高可用性）</h4><p>普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。但是你<strong>创建的 queue，只会放在一个 RabbitMQ 实例上</strong>，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。</p><p><img src="/img/mq-7.png" alt="mq-7"></p><p>这种方式确实很麻烦，也不怎么好，<strong>没做到所谓的分布式</strong>，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有<strong>数据拉取的开销</strong>，后者导致<strong>单实例性能瓶颈</strong>。</p><p>而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你<strong>开启了消息持久化</strong>，让 RabbitMQ 落地存储消息的话，<strong>消息不一定会丢</strong>，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。</p><p>所以这个事儿就比较尴尬了，这就<strong>没有什么所谓的高可用性</strong>，<strong>这方案主要是提高吞吐量的</strong>，就是说让集群中多个节点来服务某个 queue 的读写操作。</p><h4 id="镜像集群模式（高可用性）"><a href="#镜像集群模式（高可用性）" class="headerlink" title="镜像集群模式（高可用性）"></a>镜像集群模式（高可用性）</h4><p>这种模式，才是所谓的 RabbitMQ 的高可用模式，跟普通集群模式不一样的是，你创建的 queue，无论元数据还是 queue 里的消息都会<strong>存在于多个实例上</strong>，然后每次你写消息到 queue 的时候，都会自动把<strong>消息同步</strong>到多个实例的 queue 上。</p><p><img src="/img/mq-8.png" alt="mq-8"></p><p>这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就<strong>没有扩展性可言</strong>了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。</p><p>那么<strong>如何开启这个镜像集群模式</strong>呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是<strong>镜像集群模式的策略</strong>，指定的时候可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p><h3 id="Kafka-的高可用性"><a href="#Kafka-的高可用性" class="headerlink" title="Kafka 的高可用性"></a>Kafka 的高可用性</h3><p>Kafka 一个最基本的架构认识：多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。</p><p>这就是<strong>天然的分布式消息队列</strong>，就是说一个 topic 的数据，是<strong>分散放在多个机器上的，每个机器就放一部分数据</strong>。</p><p>实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性)的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。</p><p>Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。</p><p>Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。然后所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，<strong>要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题</strong>，系统复杂度太高，很容易出问题。Kafka 会均匀的将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。</p><p><img src="/img/mq-9.png" alt="mq-9"></p><p>这么搞，就有所谓的<strong>高可用性</strong>了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的，如果这上面有某个 partition 的 leader，那么此时会<strong>重新选举</strong>一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。</p><p><strong>写数据</strong>的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）</p><p><strong>消费</strong>的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。</p><p>看到这里，相信你大致明白了 Kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 Kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过┭┮﹏┭┮。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「消息队列」 为什么使用消息队列</title>
      <link href="/mq-knowledge/why-mq.html"/>
      <url>/mq-knowledge/why-mq.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><ul><li>为什么使用消息队列？</li><li>消息队列有什么优点和缺点？</li><li>Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？</li></ul><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实面试官主要是想看看：</p><ul><li><p><strong>第一</strong>，你知不知道你们系统里为什么要用消息队列这个东西？<br><br>不少候选人，说自己项目里用了 Redis、MQ，但是其实他并不知道自己为什么要用这个东西。其实说白了，就是为了用而用，或者是别人设计的架构，他从头到尾都没思考过。<br><br>没有对自己的架构问过为什么的人，一定是平时没有思考的人，面试官对这类候选人印象通常很不好。因为面试官担心你进了团队之后只会木头木脑的干呆活儿，不会自己思考。</p></li><li><p><strong>第二</strong>，你既然用了消息队列这个东西，你知不知道用了有什么好处&amp;坏处？<br><br>你要是没考虑过这个，那你盲目弄个 MQ 进系统里，后面出了问题你是不是就自己溜了给公司留坑？你要是没考虑过引入一个技术可能存在的弊端和风险，面试官把这类候选人招进来了，基本可能就是挖坑型选手。就怕你干 1 年挖一堆坑，自己跳槽了，给公司留下无穷后患。</p></li><li><p><strong>第三</strong>，既然你用了 MQ，可能是某一种 MQ，那么你当时做没做过调研？<br><br>你别傻乎乎的自己拍脑袋看个人喜好就瞎用了一个 MQ，比如 Kafka，甚至都从没调研过业界流行的 MQ 到底有哪几种。每一个 MQ 的优点和缺点是什么。每一个 MQ <strong>没有绝对的好坏</strong>，但是就是看用在哪个场景可以<strong>扬长避短，利用其优势，规避其劣势</strong>。<br><br>如果是一个不考虑技术选型的候选人招进了团队，leader 交给他一个任务，去设计个什么系统，他在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑。</p></li></ul><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么使用消息队列"><a href="#为什么使用消息队列" class="headerlink" title="为什么使用消息队列"></a>为什么使用消息队列</h3><p>其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？</p><p>面试官问你这个问题，<strong>期望的一个回答</strong>是说，你们公司有个什么<strong>业务场景</strong>，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。</p><p>先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p><h4 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h4><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃……</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454712/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-1.png" alt="img"></p><p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454743/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-2.png" alt="img"></p><p><strong>总结</strong>：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。</p><p><strong>面试技巧</strong>：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454744/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-3.png" alt="img"></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。</p><p>如果<strong>使用 MQ</strong>，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454744/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-4.png" alt="img"></p><h4 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h4><p>每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p><p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454745/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-5.png" alt="img"></p><p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454745/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-6.png" alt="img"></p><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。</p><h3 id="消息队列有什么优缺点"><a href="#消息队列有什么优缺点" class="headerlink" title="消息队列有什么优缺点"></a>消息队列有什么优缺点</h3><p>优点上面已经说了，就是<strong>在特殊场景下有其对应的好处</strong>，<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p><p>缺点有以下几个：</p><ul><li><p>系统可用性降低<br><br>系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以<a href="/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md">点击这里查看</a>。</p></li><li><p>系统复杂度提高<br><br>硬生生加个 MQ 进来，你怎么<a href="/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md">保证消息没有重复消费</a>？怎么<a href="/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md">处理消息丢失的情况</a>？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p></li><li><p>一致性问题<br><br>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p></li></ul><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。</p><h3 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？"><a href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？" class="headerlink" title="Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？"></a>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</h3><table><thead><tr><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>同 ActiveMQ</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr><tr><td>topic 数量对吞吐量的影响</td><td></td><td></td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td></td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr><tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr></tbody></table><p>综上，各种对比之后，有如下建议：</p><p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；</p><p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</p><p>不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。</p><p>所以<strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p><p>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[分布式] Zookeeper</title>
      <link href="/distributed-system/zookeeper-application-scenarios.html"/>
      <url>/distributed-system/zookeeper-application-scenarios.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>zookeeper 都有哪些使用场景？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>现在聊的 topic 是分布式系统，面试官跟你聊完了 dubbo 相关的一些问题之后，已经确认你对分布式服务框架/RPC框架基本都有一些认知了。那么他可能开始要跟你聊分布式相关的其它问题了。</p><p>分布式锁这个东西，很常用的，你做 Java系统开发，分布式系统，可能会有一些场景会用到。最常用的分布式锁就是基于 zookeeper 来实现的。</p><p>其实说实话，问这个问题，一般就是看看你是否了解 zookeeper，因为 zk 是分布式系统中很常见的一个基础系统。而且问的话常问的就是说 zk 的使用场景是什么？看你知道不知道一些基本的使用场景。但是其实 zk 挖深了自然是可以问的很深很深的。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>大致来说，zk 的使用场景如下，我就举几个简单的，大家能说几个就好了：</p><ul><li>分布式协调</li><li>分布式锁</li><li>元数据/配置信息管理</li><li>HA高可用性</li></ul><h3 id="分布式协调"><a href="#分布式协调" class="headerlink" title="分布式协调"></a>分布式协调</h3><p>这个其实是 zk 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zk 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zk 上<strong>对某个节点的值注册个监听器</strong>，一旦 B 系统处理完了就修改 zk 那个节点的值，A 立马就可以收到通知，完美解决。</p><p>  <img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544358082/zookeeper-distributed-coordination.png"></p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zk 分布式锁，一个机器接收到了请求之后先获取 zk 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也<strong>尝试去创建</strong>那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。</p><p><img src="/img/zookeeper-distributed-lock-demo.png" alt="zookeeper-distributed-lock-demo"></p><h3 id="元数据-配置信息管理"><a href="#元数据-配置信息管理" class="headerlink" title="元数据/配置信息管理"></a>元数据/配置信息管理</h3><p>zk 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zk 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zk 么？</p><p><img src="/img/zookeeper-meta-data-manage.png" alt="zookeeper-meta-data-manage"></p><h3 id="HA高可用性"><a href="#HA高可用性" class="headerlink" title="HA高可用性"></a>HA高可用性</h3><p>这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zk 来开发 HA 高可用机制，就是一个<strong>重要进程一般会做主备</strong>两个，主进程挂了立马通过 zk 感知到切换到备用进程。</p><p><img src="/img/zookeeper-active-standby.png" alt="zookeeper-active-standby"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis Redis介绍</title>
      <link href="/redis/redis-introduction.html"/>
      <url>/redis/redis-introduction.html</url>
      
        <content type="html"><![CDATA[<h2 id="一、redis是什么？（what）"><a href="#一、redis是什么？（what）" class="headerlink" title="一、redis是什么？（what）"></a>一、redis是什么？（what）</h2><p>Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。</p><p>Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。</p><h2 id="二、为什么使用redis？（why）"><a href="#二、为什么使用redis？（why）" class="headerlink" title="二、为什么使用redis？（why）"></a>二、为什么使用redis？（why）</h2><h3 id="（一）redis的特点"><a href="#（一）redis的特点" class="headerlink" title="（一）redis的特点"></a>（一）redis的特点</h3><ol><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份。</li></ol><h3 id="（二）redis的优势"><a href="#（二）redis的优势" class="headerlink" title="（二）redis的优势"></a>（二）redis的优势</h3><ol><li>性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。</li><li>丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。</li><li>原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。</li><li>丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。</li></ol><h3 id="（三）redis与其他key-value存储有什么不同"><a href="#（三）redis与其他key-value存储有什么不同" class="headerlink" title="（三）redis与其他key-value存储有什么不同"></a>（三）redis与其他key-value存储有什么不同</h3><ol><li>Redis有着更为复杂的数据结构并且提供对他们的原子性操作，Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。</li><li>Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存。</li><li>相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。</li><li>在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。</li></ol><h2 id="三、如何使用redis？（how）"><a href="#三、如何使用redis？（how）" class="headerlink" title="三、如何使用redis？（how）"></a>三、如何使用redis？（how）</h2><h3 id="（一）redis的数据类型"><a href="#（一）redis的数据类型" class="headerlink" title="（一）redis的数据类型"></a>（一）redis的数据类型</h3><table><thead><tr><th>数据类型</th><th>概念</th><th>常用命令</th></tr></thead><tbody><tr><td>String(字符串)</td><td>key-value型</td><td>SET ，GET</td></tr><tr><td>Hash(哈希)</td><td>field-value,适用于存储对象类型（对象名-对象属性值）</td><td>HMSET，HEGTALL</td></tr><tr><td>List(列表)</td><td>string类型的有序列表，按照插入顺序排序</td><td>lpush，lrange</td></tr><tr><td>Set(集合)</td><td>string类型的无序集合</td><td>sadd，smembers</td></tr><tr><td>zset(sorted set：有序集合)</td><td>string类型元素的集合,且不允许重复的成员。每个元素关联一个double值来进行排序，double值可以重复但元素不能重复。</td><td>zadd，ZRANGEBYSCORE</td></tr></tbody></table><h3 id="（二）redis常用命令"><a href="#（二）redis常用命令" class="headerlink" title="（二）redis常用命令"></a>（二）redis常用命令</h3>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Redis] Redis常见知识点总结</title>
      <link href="/redis/redis-introduce.html"/>
      <url>/redis/redis-introduce.html</url>
      
        <content type="html"><![CDATA[<!-- GFM-TOC --><ul><li><a href="#一redis-是什么">一、Redis 是什么</a></li><li><a href="#二五种基本类型">二、五种基本类型</a><ul><li><a href="#1-string">1. STRING</a></li><li><a href="#2-list">2. LIST</a></li><li><a href="#3-set">3. SET</a></li><li><a href="#4-hash">4. HASH</a></li><li><a href="#5-zset">5. ZSET</a></li></ul></li><li><a href="#三键的过期时间">三、键的过期时间</a></li><li><a href="#四发布与订阅">四、发布与订阅</a></li><li><a href="#五事务">五、事务</a></li><li><a href="#六持久化">六、持久化</a><ul><li><a href="#1-快照持久化">1. 快照持久化</a></li><li><a href="#2-aof-持久化">2. AOF 持久化</a></li></ul></li><li><a href="#七复制">七、复制</a><ul><li><a href="#从服务器连接主服务器的过程">从服务器连接主服务器的过程</a></li><li><a href="#主从链">主从链</a></li></ul></li><li><a href="#八处理故障">八、处理故障</a></li><li><a href="#九分片">九、分片</a><ul><li><a href="#1-客户端分片">1. 客户端分片</a></li><li><a href="#2-代理分片">2. 代理分片</a></li><li><a href="#3-服务器分片">3. 服务器分片</a></li></ul></li><li><a href="#十事件">十、事件</a><ul><li><a href="#事件类型">事件类型</a></li><li><a href="#事件的调度与执行">事件的调度与执行</a></li></ul></li><li><a href="#十一redis-与-memcached-的区别">十一、Redis 与 Memcached 的区别</a><ul><li><a href="#数据类型">数据类型</a></li><li><a href="#数据持久化">数据持久化</a></li><li><a href="#分布式">分布式</a></li><li><a href="#内存管理机制">内存管理机制</a></li></ul></li><li><a href="#十二redis-适用场景">十二、Redis 适用场景</a><ul><li><a href="#缓存">缓存</a></li><li><a href="#消息队列">消息队列</a></li><li><a href="#计数器">计数器</a></li><li><a href="#好友关系">好友关系</a></li></ul></li><li><a href="#十三数据淘汰策略">十三、数据淘汰策略</a></li><li><a href="#十四一个简单的论坛系统分析">十四、一个简单的论坛系统分析</a><ul><li><a href="#文章信息">文章信息</a></li><li><a href="#点赞功能">点赞功能</a></li><li><a href="#对文章进行排序">对文章进行排序</a></li></ul></li><li><a href="#参考资料">参考资料</a><!-- GFM-TOC --></li></ul><h1 id="一、Redis-是什么"><a href="#一、Redis-是什么" class="headerlink" title="一、Redis 是什么"></a>一、Redis 是什么</h1><p>Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。</p><p>五种类型数据类型为：字符串、列表、集合、有序集合、散列表。</p><p>Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。</p><h1 id="二、五种基本类型"><a href="#二、五种基本类型" class="headerlink" title="二、五种基本类型"></a>二、五种基本类型</h1><table><thead><tr><th style="text-align:center">数据类型</th><th style="text-align:center">可以存储的值</th><th style="text-align:center">操作</th></tr></thead><tbody><tr><td style="text-align:center">STRING</td><td style="text-align:center">字符串、整数或者浮点数</td><td style="text-align:center">对整个字符串或者字符串的其中一部分执行操作<br> 对整数和浮点数执行自增或者自减操作</td></tr><tr><td style="text-align:center">LIST</td><td style="text-align:center">链表</td><td style="text-align:center">从两端压入或者弹出元素<br> 读取单个或者多个元素<br> 进行修剪，只保留一个范围内的元素</td></tr><tr><td style="text-align:center">SET</td><td style="text-align:center">无序集合</td><td style="text-align:center">添加、获取、移除单个元素<br> 检查一个元素是否存在于集合中<br> 计算交集、并集、差集<br> 从集合里面随机获取元素</td></tr><tr><td style="text-align:center">HASH</td><td style="text-align:center">包含键值对的无序散列表</td><td style="text-align:center">添加、获取、移除单个键值对<br> 获取所有键值对<br> 检查某个键是否存在</td></tr><tr><td style="text-align:center">ZSET</td><td style="text-align:center">有序集合</td><td style="text-align:center">添加、获取、删除元素<br> 根据分值范围或者成员来获取元素<br> 计算一个键的排名</td></tr></tbody></table><blockquote><p><a href="https://redislabs.com/ebook/part-1-getting-started/chapter-1-getting-to-know-redis/1-2-what-redis-data-structures-look-like/" target="_blank" rel="noopener">What Redis data structures look like</a></p></blockquote><h2 id="1-STRING"><a href="#1-STRING" class="headerlink" title="1. STRING"></a>1. STRING</h2><p><div align="center"> <img src="../pics//6019b2db-bc3e-4408-b6d8-96025f4481d6.png" width="400"> </div><br></p><pre class=" language-html"><code class="language-html">> set hello worldOK> get hello"world"> del hello(integer) 1> get hello(nil)</code></pre><h2 id="2-LIST"><a href="#2-LIST" class="headerlink" title="2. LIST"></a>2. LIST</h2><p><div align="center"> <img src="../pics//fb327611-7e2b-4f2f-9f5b-38592d408f07.png" width="400"> </div><br></p><pre class=" language-html"><code class="language-html">> rpush list-key item(integer) 1> rpush list-key item2(integer) 2> rpush list-key item(integer) 3> lrange list-key 0 -11) "item"2) "item2"3) "item"> lindex list-key 1"item2"> lpop list-key"item"> lrange list-key 0 -11) "item2"2) "item"</code></pre><h2 id="3-SET"><a href="#3-SET" class="headerlink" title="3. SET"></a>3. SET</h2><p><div align="center"> <img src="../pics//cd5fbcff-3f35-43a6-8ffa-082a93ce0f0e.png" width="400"> </div><br></p><pre class=" language-html"><code class="language-html">> sadd set-key item(integer) 1> sadd set-key item2(integer) 1> sadd set-key item3(integer) 1> sadd set-key item(integer) 0> smembers set-key1) "item"2) "item2"3) "item3"> sismember set-key item4(integer) 0> sismember set-key item(integer) 1> srem set-key item2(integer) 1> srem set-key item2(integer) 0> smembers set-key1) "item"2) "item3"</code></pre><h2 id="4-HASH"><a href="#4-HASH" class="headerlink" title="4. HASH"></a>4. HASH</h2><p><div align="center"> <img src="../pics//7bd202a7-93d4-4f3a-a878-af68ae25539a.png" width="400"> </div><br></p><pre class=" language-html"><code class="language-html">> hset hash-key sub-key1 value1(integer) 1> hset hash-key sub-key2 value2(integer) 1> hset hash-key sub-key1 value1(integer) 0> hgetall hash-key1) "sub-key1"2) "value1"3) "sub-key2"4) "value2"> hdel hash-key sub-key2(integer) 1> hdel hash-key sub-key2(integer) 0> hget hash-key sub-key1"value1"> hgetall hash-key1) "sub-key1"2) "value1"</code></pre><h2 id="5-ZSET"><a href="#5-ZSET" class="headerlink" title="5. ZSET"></a>5. ZSET</h2><p><div align="center"> <img src="../pics//1202b2d6-9469-4251-bd47-ca6034fb6116.png" width="400"> </div><br></p><pre class=" language-html"><code class="language-html">> zadd zset-key 728 member1(integer) 1> zadd zset-key 982 member0(integer) 1> zadd zset-key 982 member0(integer) 0> zrange zset-key 0 -1 withscores1) "member1"2) "728"3) "member0"4) "982"> zrangebyscore zset-key 0 800 withscores1) "member1"2) "728"> zrem zset-key member1(integer) 1> zrem zset-key member1(integer) 0> zrange zset-key 0 -1 withscores1) "member0"2) "982"</code></pre><h1 id="三、键的过期时间"><a href="#三、键的过期时间" class="headerlink" title="三、键的过期时间"></a>三、键的过期时间</h1><p>Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。</p><p>对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。</p><p>过期时间对于清理缓存数据非常有用。</p><h1 id="四、发布与订阅"><a href="#四、发布与订阅" class="headerlink" title="四、发布与订阅"></a>四、发布与订阅</h1><p>发布与订阅实际上是观察者模式，订阅者订阅了频道之后，发布者向频道发送字符串消息会被所有订阅者接收到。</p><p>发布与订阅有一些问题，很少使用它，而是使用替代的解决方案。问题如下：</p><ol><li>如果订阅者读取消息的速度很慢，会使得消息不断积压在发布者的输出缓存区中，造成内存占用过多；</li><li>如果订阅者在执行订阅的过程中网络出现问题，那么就会丢失断线期间发送的所有消息。</li></ol><h1 id="五、事务"><a href="#五、事务" class="headerlink" title="五、事务"></a>五、事务</h1><p>Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。</p><p>MULTI 和 EXEC 中的操作将会一次性发送给服务器，而不是一条一条发送，这种方式称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。</p><h1 id="六、持久化"><a href="#六、持久化" class="headerlink" title="六、持久化"></a>六、持久化</h1><p>Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。</p><h2 id="1-快照持久化"><a href="#1-快照持久化" class="headerlink" title="1. 快照持久化"></a>1. 快照持久化</h2><p>将某个时间点的所有数据都存放到硬盘上。</p><p>可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。</p><p>如果系统发生故障，将会丢失最后一次创建快照之后的数据。并且如果数据量很大，保存快照的时间也会很长。</p><h2 id="2-AOF-持久化"><a href="#2-AOF-持久化" class="headerlink" title="2. AOF 持久化"></a>2. AOF 持久化</h2><p>AOF 持久化将写命令添加到 AOF 文件（Append Only File）的末尾。</p><p>对硬盘的文件进行写入时，写入的内容首先会被存储到缓冲区，然后由操作系统决定什么时候将该内容同步到硬盘，用户可以调用 file.flush() 方法请求操作系统尽快将缓冲区存储的数据同步到硬盘。因此将写命令添加到 AOF 文件时，要根据需求来保证何时将添加的数据同步到硬盘上，有以下同步选项：</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">同步频率</th></tr></thead><tbody><tr><td style="text-align:center">always</td><td style="text-align:center">每个写命令都同步</td></tr><tr><td style="text-align:center">everysec</td><td style="text-align:center">每秒同步一次</td></tr><tr><td style="text-align:center">no</td><td style="text-align:center">让操作系统来决定何时同步</td></tr></tbody></table><p>always 选项会严重减低服务器的性能；everysec 选项比较合适，可以保证系统奔溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；no 选项并不能给服务器性能带来多大的提升，而且也会增加系统奔溃时数据丢失的数量。</p><p>随着服务器写请求的增多，AOF 文件会越来越大；Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。</p><h1 id="七、复制"><a href="#七、复制" class="headerlink" title="七、复制"></a>七、复制</h1><p>通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。</p><p>一个从服务器只能有一个主服务器，并且不支持主主复制。</p><h2 id="从服务器连接主服务器的过程"><a href="#从服务器连接主服务器的过程" class="headerlink" title="从服务器连接主服务器的过程"></a>从服务器连接主服务器的过程</h2><ol><li><p>主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；</p></li><li><p>从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；</p></li><li><p>主服务器每执行一次写命令，就向从服务器发送相同的写命令。</p></li></ol><h2 id="主从链"><a href="#主从链" class="headerlink" title="主从链"></a>主从链</h2><p>随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。</p><p><div align="center"> <img src="../pics//395a9e83-b1a1-4a1d-b170-d081e7bb5bab.png" width="600"> </div><br></p><h1 id="八、处理故障"><a href="#八、处理故障" class="headerlink" title="八、处理故障"></a>八、处理故障</h1><p>要用到持久化文件来恢复服务器的数据。</p><p>持久化文件可能因为服务器出错也有错误，因此要先对持久化文件进行验证和修复。对 AOF 文件就行验证和修复很容易，修复操作将第一个出错命令和其后的所有命令都删除；但是只能验证快照文件，无法对快照文件进行修复，因为快照文件进行了压缩，出现在快照文件中间的错误可能会导致整个快照文件的剩余部分无法读取。</p><p>当主服务器出现故障时，Redis 常用的做法是新开一台服务器作为主服务器，具体步骤如下：假设 A 为主服务器，B 为从服务器，当 A 出现故障时，让 B 生成一个快照文件，将快照文件发送给 C，并让 C 恢复快照文件的数据。最后，让 B 成为 C 的从服务器。</p><h1 id="九、分片"><a href="#九、分片" class="headerlink" title="九、分片"></a>九、分片</h1><p>Redis 中的分片类似于 MySQL 的分表操作，分片是将数据划分为多个部分的方法，对数据的划分可以基于键包含的 ID、基于键的哈希值，或者基于以上两者的某种组合。通过对数据进行分片，用户可以将数据存储到多台机器里面，也可以从多台机器里面获取数据，这种方法在解决某些问题时可以获得线性级别的性能提升。</p><p>假设有 4 个 Reids 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，… 等等，有不同的方式来选择一个指定的键存储在哪个实例中。最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。</p><h2 id="1-客户端分片"><a href="#1-客户端分片" class="headerlink" title="1. 客户端分片"></a>1. 客户端分片</h2><p>客户端使用一致性哈希等算法决定键应当分布到哪个节点。</p><h2 id="2-代理分片"><a href="#2-代理分片" class="headerlink" title="2. 代理分片"></a>2. 代理分片</h2><p>将客户端请求发送到代理上，由代理转发请求到正确的节点上。</p><h2 id="3-服务器分片"><a href="#3-服务器分片" class="headerlink" title="3. 服务器分片"></a>3. 服务器分片</h2><p>Redis Cluster。</p><h1 id="十、事件"><a href="#十、事件" class="headerlink" title="十、事件"></a>十、事件</h1><h2 id="事件类型"><a href="#事件类型" class="headerlink" title="事件类型"></a>事件类型</h2><h3 id="1-文件事件"><a href="#1-文件事件" class="headerlink" title="1. 文件事件"></a>1. 文件事件</h3><p>服务器有许多套接字，事件产生时会对这些套接字进行操作，服务器通过监听套接字来处理事件。常见的文件事件有：客户端的连接事件；客户端的命令请求事件；服务器向客户端返回命令结果的事件；</p><h3 id="2-时间事件"><a href="#2-时间事件" class="headerlink" title="2. 时间事件"></a>2. 时间事件</h3><p>又分为两类：定时事件是让一段程序在指定的时间之内执行一次；周期性时间是让一段程序每隔指定时间就执行一次。</p><h2 id="事件的调度与执行"><a href="#事件的调度与执行" class="headerlink" title="事件的调度与执行"></a>事件的调度与执行</h2><p>服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能监听太久，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。</p><p>事件调度与执行由 aeProcessEvents 函数负责，伪代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">aeProcessEvents</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 获取到达时间离当前时间最接近的时间事件</span>    time_event <span class="token operator">=</span> aeSearchNearestTimer<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 计算最接近的时间事件距离到达还有多少毫秒</span>    remaind_ms <span class="token operator">=</span> time_event<span class="token punctuation">.</span>when <span class="token operator">-</span> unix_ts_now<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0</span>    <span class="token keyword">if</span> remaind_ms <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>        remaind_ms <span class="token operator">=</span> <span class="token number">0</span>    <span class="token comment" spellcheck="true"># 根据 remaind_ms 的值，创建 timeval</span>    timeval <span class="token operator">=</span> create_timeval_with_ms<span class="token punctuation">(</span>remaind_ms<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定</span>    aeApiPoll<span class="token punctuation">(</span>timeval<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 处理所有已产生的文件事件</span>    procesFileEvents<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 处理所有已到达的时间事件</span>    processTimeEvents<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 初始化服务器</span>    init_server<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 一直处理事件，直到服务器关闭为止</span>    <span class="token keyword">while</span> server_is_not_shutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        aeProcessEvents<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 服务器关闭，执行清理操作</span>    clean_server<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>从事件处理的角度来看，服务器运行流程如下：</p><p><div align="center"> <img src="../pics//73b73189-9e95-47e5-91d0-9378b8462e15.png"> </div><br></p><h1 id="十一、Redis-与-Memcached-的区别"><a href="#十一、Redis-与-Memcached-的区别" class="headerlink" title="十一、Redis 与 Memcached 的区别"></a>十一、Redis 与 Memcached 的区别</h1><p>两者都是非关系型内存键值数据库。有以下主要不同：</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>Memcached 仅支持字符串类型，而 Redis 支持五种不同种类的数据类型，使得它可以更灵活地解决问题。</p><h2 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h2><p>Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。</p><h2 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h2><p>Memcached 不支持分布式，只能通过在客户端使用像一致性哈希这样的分布式算法来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。</p><p>Redis Cluster 实现了分布式的支持。</p><h2 id="内存管理机制"><a href="#内存管理机制" class="headerlink" title="内存管理机制"></a>内存管理机制</h2><p>在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘。而 Memcached 的数据则会一直在内存中。</p><p>Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题，但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。</p><h1 id="十二、Redis-适用场景"><a href="#十二、Redis-适用场景" class="headerlink" title="十二、Redis 适用场景"></a>十二、Redis 适用场景</h1><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>s使用 Redis 作为缓存，将热点数据放到内存中。</p><h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><p>Redis 的 List 类型是双向链表，很适合用于消息队列。</p><h2 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h2><p>Redis 这种内存数据库才能支持计数器的频繁读写操作。</p><h2 id="好友关系"><a href="#好友关系" class="headerlink" title="好友关系"></a>好友关系</h2><p>使用 set 类型的交集很容易就可以知道两个用户的共同好友。</p><h1 id="十三、数据淘汰策略"><a href="#十三、数据淘汰策略" class="headerlink" title="十三、数据淘汰策略"></a>十三、数据淘汰策略</h1><p>可以设置内存最大使用量，当内存使用量超过时施行淘汰策略，具体有 6 种淘汰策略。</p><table><thead><tr><th>策略</th><th>描述</th></tr></thead><tbody><tr><td>volatile-lru</td><td>从已设置过期时间的数据集中挑选最近最少使用的数据淘汰</td></tr><tr><td>volatile-ttl</td><td>从已设置过期时间的数据集中挑选将要过期的数据淘汰</td></tr><tr><td>volatile-random</td><td>从已设置过期时间的数据集中任意选择数据淘汰</td></tr><tr><td>allkeys-lru</td><td>从所有数据集中挑选最近最少使用的数据淘汰</td></tr><tr><td>allkeys-random</td><td>从所有数据集中任意选择数据进行淘汰</td></tr><tr><td>no-envicition</td><td>禁止驱逐数据</td></tr></tbody></table><p>如果使用 Redis 来缓存数据时，要保证所有数据都是热点数据，可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。</p><h1 id="十四、一个简单的论坛系统分析"><a href="#十四、一个简单的论坛系统分析" class="headerlink" title="十四、一个简单的论坛系统分析"></a>十四、一个简单的论坛系统分析</h1><p>该论坛系统功能如下：</p><ul><li>可以发布文章；</li><li>可以对文章进行点赞；</li><li>在首页可以按文章的发布时间或者文章的点赞数进行排序显示；</li></ul><h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。</p><p>Redis 没有关系型数据库中的表这一概念来将同类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。</p><p><div align="center"> <img src="../pics//7c54de21-e2ff-402e-bc42-4037de1c1592.png" width="400"> </div><br></p><h2 id="点赞功能"><a href="#点赞功能" class="headerlink" title="点赞功能"></a>点赞功能</h2><p>当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。</p><p>为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。</p><p><div align="center"> <img src="../pics//485fdf34-ccf8-4185-97c6-17374ee719a0.png" width="400"> </div><br></p><h2 id="对文章进行排序"><a href="#对文章进行排序" class="headerlink" title="对文章进行排序"></a>对文章进行排序</h2><p>为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）</p><p><div align="center"> <img src="../pics//f7d170a3-e446-4a64-ac2d-cb95028f81a8.png" width="800"> </div><br></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li>Carlson J L. Redis in Action[J]. Media.johnwiley.com.au, 2013.</li><li>黄健宏. Redis 设计与实现 [M]. 机械工业出版社, 2014.</li><li><a href="https://redislabs.com/ebook/foreword/" target="_blank" rel="noopener">REDIS IN ACTION</a></li><li><a href="http://www.cnblogs.com/loveincode/p/7411911.html" target="_blank" rel="noopener">论述 Redis 和 Memcached 的差异</a></li><li><a href="http://wiki.jikexueyuan.com/project/redis-guide" target="_blank" rel="noopener">Redis 3.0 中文版- 分片</a></li><li><a href="http://www.scienjus.com/redis-use-case/" target="_blank" rel="noopener">Redis 应用场景</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Redis] Redis集群模式部署</title>
      <link href="/redis/redis-cluster.html"/>
      <url>/redis/redis-cluster.html</url>
      
        <content type="html"><![CDATA[<h2 id="1-Redis部署"><a href="#1-Redis部署" class="headerlink" title="1. Redis部署"></a>1. Redis部署</h2><blockquote><p>以下以Linux系统为例</p></blockquote><h3 id="1-1-下载和编译"><a href="#1-1-下载和编译" class="headerlink" title="1.1 下载和编译"></a>1.1 下载和编译</h3><pre class=" language-shell"><code class="language-shell">$ wget http://download.redis.io/releases/redis-4.0.7.tar.gz$ tar xzf redis-4.0.7.tar.gz$ cd redis-4.0.7$ make</code></pre><p>编译完成后会在<code>src</code>目录下生成Redis服务端程序<code>redis-server</code>和客户端程序<code>redis-cli</code>。</p><h3 id="1-2-启动服务"><a href="#1-2-启动服务" class="headerlink" title="1.2 启动服务"></a>1.2 启动服务</h3><p><strong>1、前台运行</strong></p><pre class=" language-shell"><code class="language-shell">src/redis-server</code></pre><p>该方式启动默认为<code>前台方式</code>运行，使用默认配置。</p><p><strong>2、后台运行</strong></p><p>可以修改<code>redis.conf</code>文件的<code>daemonize</code>参数为<code>yes</code>，指定配置文件启动，例如：</p><pre class=" language-shell"><code class="language-shell">vi redis.conf# By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes</code></pre><p>指定配置文件启动。</p><pre class=" language-shell"><code class="language-shell">src/redis-server redis.conf</code></pre><p>例如：</p><pre class=" language-shell"><code class="language-shell">#指定配置文件后台启动[root@kube-node-1 redis-4.0.7]# src/redis-server redis.conf95778:C 30 Jan 00:44:37.633 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo95778:C 30 Jan 00:44:37.634 # Redis version=4.0.7, bits=64, commit=00000000, modified=0, pid=95778, just started95778:C 30 Jan 00:44:37.634 # Configuration loaded#查看Redis进程[root@kube-node-1 redis-4.0.7]# ps aux|grep redisroot      95779  0.0  0.0 145268   468 ?        Ssl  00:44   0:00 src/redis-server 127.0.0.1:6379</code></pre><p>更多启动参数如下：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 src]# ./redis-server --helpUsage: ./redis-server [/path/to/redis.conf] [options]       ./redis-server - (read config from stdin)       ./redis-server -v or --version       ./redis-server -h or --help       ./redis-server --test-memory <megabytes>Examples:       ./redis-server (run the server with default conf)       ./redis-server /etc/redis/6379.conf       ./redis-server --port 7777       ./redis-server --port 7777 --slaveof 127.0.0.1 8888       ./redis-server /etc/myredis.conf --loglevel verboseSentinel mode:       ./redis-server /etc/sentinel.conf --sentinel</code></pre><h3 id="1-3-客户端测试"><a href="#1-3-客户端测试" class="headerlink" title="1.3 客户端测试"></a>1.3 客户端测试</h3><pre class=" language-shell"><code class="language-shell">$ src/redis-cliredis> set foo barOKredis> get foo"bar"</code></pre><h2 id="2-Redis集群部署"><a href="#2-Redis集群部署" class="headerlink" title="2. Redis集群部署"></a>2. Redis集群部署</h2><p>Redis的集群部署需要在每台集群部署的机器上安装Redis（可参考上述的[Redis安装] ），然后修改配置以集群的方式启动。</p><h3 id="2-1-手动部署集群"><a href="#2-1-手动部署集群" class="headerlink" title="2.1 手动部署集群"></a>2.1 手动部署集群</h3><h4 id="2-1-1-设置配置文件及启动实例"><a href="#2-1-1-设置配置文件及启动实例" class="headerlink" title="2.1.1 设置配置文件及启动实例"></a>2.1.1 设置配置文件及启动实例</h4><p>修改配置文件redis.conf，集群模式的最小化配置文件如下：</p><pre class=" language-shell"><code class="language-shell">#可选操作，该项设置后台方式运行，daemonize yesport 7000cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yes</code></pre><blockquote><p>更多集群配置参数可参考默认配置文件redis.conf中<code>Cluster</code>模块的说明</p></blockquote><p>最小集群模式需要三个master实例，一般建议起六个实例，即三主三从。因此我们创建6个以端口号命名的目录存放实例的配置文件和其他信息。</p><pre class=" language-shell"><code class="language-shell">mkdir cluster-testcd cluster-testmkdir 7000 7001 7002 7003 7004 7005</code></pre><p>在对应端口号的目录中创建<code>redis.conf</code>的文件，配置文件的内容可参考上述的集群模式配置。每个配置文件中的端口号<code>port</code>参数改为对应目录的端口号。</p><p>复制<code>redis-server</code>的二进制文件到<code>cluster-test</code>目录中，通过指定配置文件的方式启动<code>redis</code>服务，例如：</p><pre class=" language-shell"><code class="language-shell">cd 7000../redis-server ./redis.conf</code></pre><p>如果是以前台方式运行，则会在控制台输出以下信息：</p><pre class=" language-shell"><code class="language-shell">[82462] 26 Nov 11:56:55.329 * No cluster configuration found, I'm 97a3a64667477371c4479320d683e4c8db5858b1</code></pre><p>每个实例都会生成一个<code>Node ID</code>，类似<code>97a3a64667477371c4479320d683e4c8db5858b1</code>，用来作为Redis实例在集群中的唯一标识，而不是通过IP和Port，IP和Port可能会改变，该<code>Node ID</code>不会改变。</p><p>目录结构可参考：</p><pre class=" language-shell"><code class="language-shell">cluster-test/├── 7000│   ├── appendonly.aof│   ├── dump.rdb│   ├── nodes.conf│   └── redis.conf├── 7001│   ├── appendonly.aof│   ├── dump.rdb│   ├── nodes.conf│   └── redis.conf├── 7002│   ├── appendonly.aof│   ├── dump.rdb│   ├── nodes.conf│   └── redis.conf├── 7003│   ├── appendonly.aof│   ├── dump.rdb│   ├── nodes.conf│   └── redis.conf├── 7004│   ├── appendonly.aof│   ├── dump.rdb│   ├── nodes.conf│   └── redis.conf├── 7005│   ├── appendonly.aof│   ├── dump.rdb│   ├── nodes.conf│   └── redis.conf├── redis-cli└── redis-server</code></pre><h4 id="2-1-2-redis-trib创建集群"><a href="#2-1-2-redis-trib创建集群" class="headerlink" title="2.1.2 redis-trib创建集群"></a>2.1.2 redis-trib创建集群</h4><p>Redis的实例全部运行之后，还需要<code>redis-trib.rb</code>工具来完成集群的创建，<code>redis-trib.rb</code>二进制文件在Redis包主目录下的<code>src</code>目录中，运行该工具依赖<code>Ruby</code>环境和<code>gem</code>，因此需要提前安装。</p><p><strong>1、安装Ruby</strong></p><pre class=" language-shell"><code class="language-shell">yum -y install ruby rubygems</code></pre><p>查看Ruby版本信息。</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 src]# ruby --versionruby 2.0.0p648 (2015-12-16) [x86_64-linux]</code></pre><p>由于<code>centos</code>系统默认支持Ruby版本为<code>2.0.0</code>，因此执行<code>gem install redis</code>命令时会报以下错误。</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 src]# gem install redisFetching: redis-4.0.1.gem (100%)ERROR:  Error installing redis:    redis requires Ruby version >= 2.2.2.</code></pre><p>解决方法是先安装<code>rvm</code>，再升级<code>ruby</code>版本。</p><p><strong>2、安装rvm</strong></p><pre class=" language-shell"><code class="language-shell">curl -L get.rvm.io | bash -s stable</code></pre><p>如果遇到以下报错，则执行报错中的<code>gpg2 --recv-keys</code>的命令。</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 ~]# curl -L get.rvm.io | bash -s stable  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100   194  100   194    0     0    335      0 --:--:-- --:--:-- --:--:--   335100 24090  100 24090    0     0  17421      0  0:00:01  0:00:01 --:--:-- 44446Downloading https://github.com/rvm/rvm/archive/1.29.3.tar.gzDownloading https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.ascgpg: 于 2017年09月11日 星期一 04时59分21秒 CST 创建的签名，使用 RSA，钥匙号 BF04FF17gpg: 无法检查签名：没有公钥Warning, RVM 1.26.0 introduces signed releases and automated check of signatures when GPG software found. Assuming you trust Michal Papis import the mpapis public key (downloading the signatures).GPG signature verification failed for '/usr/local/rvm/archives/rvm-1.29.3.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.asc'! Try to install GPG v2 and then fetch the public key:    gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3or if it fails:    command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import -the key can be compared with:    https://rvm.io/mpapis.asc    https://keybase.io/mpapisNOTE: GPG version 2.1.17 have a bug which cause failures during fetching keys from remote server. Please downgrade or upgrade to newer version (if available) or use the second method described above.</code></pre><p>执行报错中的<code>gpg2 --recv-keys</code>的命令。</p><p>例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 ~]# gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3gpg: 钥匙环‘/root/.gnupg/secring.gpg’已建立gpg: 下载密钥‘D39DC0E3’，从 hkp 服务器 keys.gnupg.netgpg: /root/.gnupg/trustdb.gpg：建立了信任度数据库gpg: 密钥 D39DC0E3：公钥“Michal Papis (RVM signing) <mpapis@gmail.com>”已导入gpg: 没有找到任何绝对信任的密钥gpg: 合计被处理的数量：1gpg:           已导入：1  (RSA: 1)</code></pre><p>再次执行命令<code>curl -L get.rvm.io | bash -s stable</code>。例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 ~]# curl -L get.rvm.io | bash -s stable  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100   194  100   194    0     0    310      0 --:--:-- --:--:-- --:--:--   309100 24090  100 24090    0     0  18230      0  0:00:01  0:00:01 --:--:--  103kDownloading https://github.com/rvm/rvm/archive/1.29.3.tar.gzDownloading https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.ascgpg: 于 2017年09月11日 星期一 04时59分21秒 CST 创建的签名，使用 RSA，钥匙号 BF04FF17gpg: 完好的签名，来自于“Michal Papis (RVM signing) <mpapis@gmail.com>”gpg:               亦即“Michal Papis <michal.papis@toptal.com>”gpg:               亦即“[jpeg image of size 5015]”gpg: 警告：这把密钥未经受信任的签名认证！gpg:       没有证据表明这个签名属于它所声称的持有者。主钥指纹： 409B 6B17 96C2 7546 2A17  0311 3804 BB82 D39D C0E3子钥指纹： 62C9 E5F4 DA30 0D94 AC36  166B E206 C29F BF04 FF17GPG verified '/usr/local/rvm/archives/rvm-1.29.3.tgz'Creating group 'rvm'Installing RVM to /usr/local/rvm/Installation of RVM in /usr/local/rvm/ is almost complete:  * First you need to add all users that will be using rvm to 'rvm' group,    and logout - login again, anyone using rvm will be operating with `umask u=rwx,g=rwx,o=rx`.  * To start using RVM you need to run `source /etc/profile.d/rvm.sh`    in all your open shell windows, in rare cases you need to reopen all shell windows.</code></pre><p>以上表示执行成功，</p><pre class=" language-shell"><code class="language-shell">source /usr/local/rvm/scripts/rvm</code></pre><p>查看rvm库中已知的ruby版本</p><pre class=" language-shell"><code class="language-shell">rvm list known</code></pre><p>例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 ~]# rvm list known# MRI Rubies[ruby-]1.8.6[-p420][ruby-]1.8.7[-head] # security released on head[ruby-]1.9.1[-p431][ruby-]1.9.2[-p330][ruby-]1.9.3[-p551][ruby-]2.0.0[-p648][ruby-]2.1[.10][ruby-]2.2[.7][ruby-]2.3[.4][ruby-]2.4[.1]ruby-head...</code></pre><p><strong>3、升级Ruby</strong></p><pre class=" language-shell"><code class="language-shell">#安装rubyrvm install  2.4.0#使用新版本rvm use  2.4.0#移除旧版本rvm remove 2.0.0#查看当前版本ruby --version</code></pre><p>例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 ~]# rvm install  2.4.0Searching for binary rubies, this might take some time.Found remote file https://rvm_io.global.ssl.fastly.net/binaries/centos/7/x86_64/ruby-2.4.0.tar.bz2Checking requirements for centos.Installing requirements for centos.Installing required packages: autoconf, automake, bison, bzip2, gcc-c++, libffi-devel, libtool, readline-devel, sqlite-devel, zlib-devel, libyaml-devel, openssl-devel................................Requirements installation successful.ruby-2.4.0 - #configureruby-2.4.0 - #download  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100 14.0M  100 14.0M    0     0   852k      0  0:00:16  0:00:16 --:--:--  980kNo checksum for downloaded archive, recording checksum in user configuration.ruby-2.4.0 - #validate archiveruby-2.4.0 - #extractruby-2.4.0 - #validate binaryruby-2.4.0 - #setupruby-2.4.0 - #gemset created /usr/local/rvm/gems/ruby-2.4.0@globalruby-2.4.0 - #importing gemset /usr/local/rvm/gemsets/global.gems..............................ruby-2.4.0 - #generating global wrappers........ruby-2.4.0 - #gemset created /usr/local/rvm/gems/ruby-2.4.0ruby-2.4.0 - #importing gemsetfile /usr/local/rvm/gemsets/default.gems evaluated to empty gem listruby-2.4.0 - #generating default wrappers........[root@kube-node-1 ~]# rvm use  2.4.0Using /usr/local/rvm/gems/ruby-2.4.0[root@kube-node-1 ~]# rvm remove 2.0.0ruby-2.0.0-p648 - #already goneUsing /usr/local/rvm/gems/ruby-2.4.0[root@kube-node-1 ~]# ruby --versionruby 2.4.0p0 (2016-12-24 revision 57164) [x86_64-linux]</code></pre><p><strong>4、安装gem</strong></p><pre class=" language-shell"><code class="language-shell">gem install redis</code></pre><p>例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 ~]# gem install redisFetching: redis-4.0.1.gem (100%)Successfully installed redis-4.0.1Parsing documentation for redis-4.0.1Installing ri documentation for redis-4.0.1Done installing documentation for redis after 2 seconds1 gem installed</code></pre><p><strong>5、执行redis-trib.rb命令</strong></p><p>以上表示安装成功，可以执行<code>redis-trib.rb</code>命令。</p><pre class=" language-shell"><code class="language-shell">cd src #执行redis-trib.rb命令./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \> 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005</code></pre><p>参数<code>create</code>表示创建一个新的集群，<code>--replicas 1</code>表示为每个master创建一个slave。</p><p>如果创建成功会显示以下信息</p><pre class=" language-shell"><code class="language-shell">[OK] All 16384 slots covered</code></pre><p>例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 src]# ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \> 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005>>> Creating cluster>>> Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:7000127.0.0.1:7001127.0.0.1:7002Adding replica 127.0.0.1:7004 to 127.0.0.1:7000Adding replica 127.0.0.1:7005 to 127.0.0.1:7001Adding replica 127.0.0.1:7003 to 127.0.0.1:7002>>> Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000   slots:0-5460 (5461 slots) masterM: 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001   slots:5461-10922 (5462 slots) masterM: be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002   slots:10923-16383 (5461 slots) masterS: 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003   replicates 13d0c397604a0b2644244c37b666fce83f29faa8S: dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004   replicates be2718476eba4e56f696e56b75e67df720b7fc24S: 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005   replicates d5a834d075fd93eefab877c6ebb86efff680650fCan I set the above configuration? (type 'yes' to accept): yes>>> Nodes configuration updated>>> Assign a different config epoch to each node>>> Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join....>>> Performing Cluster Check (using node 127.0.0.1:7000)M: d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000   slots:0-5460 (5461 slots) master   1 additional replica(s)M: be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002   slots:10923-16383 (5461 slots) master   1 additional replica(s)M: 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001   slots:5461-10922 (5462 slots) master   1 additional replica(s)S: 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003   slots: (0 slots) slave   replicates 13d0c397604a0b2644244c37b666fce83f29faa8S: 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005   slots: (0 slots) slave   replicates d5a834d075fd93eefab877c6ebb86efff680650fS: dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004   slots: (0 slots) slave   replicates be2718476eba4e56f696e56b75e67df720b7fc24[OK] All nodes agree about slots configuration.>>> Check for open slots...>>> Check slots coverage...[OK] All 16384 slots covered.</code></pre><h4 id="2-1-3-部署结果验证"><a href="#2-1-3-部署结果验证" class="headerlink" title="2.1.3 部署结果验证"></a>2.1.3 部署结果验证</h4><p><strong>1、客户端访问</strong></p><p>使用客户端<code>redis-cli</code>二进制访问某个实例，执行<code>set</code>和<code>get</code>的测试。</p><pre class=" language-shell"><code class="language-shell">$ redis-cli -c -p 7000redis 127.0.0.1:7000> set foo bar-> Redirected to slot [12182] located at 127.0.0.1:7002OKredis 127.0.0.1:7002> set hello world-> Redirected to slot [866] located at 127.0.0.1:7000OKredis 127.0.0.1:7000> get foo-> Redirected to slot [12182] located at 127.0.0.1:7002"bar"redis 127.0.0.1:7000> get hello-> Redirected to slot [866] located at 127.0.0.1:7000"world"</code></pre><p><strong>2、查看集群状态</strong></p><p>使用<code>cluster info</code>命令查看集群状态。</p><pre class=" language-shell"><code class="language-shell">127.0.0.1:7000> cluster infocluster_state:ok                       #集群状态cluster_slots_assigned:16384           #被分配的槽位数cluster_slots_ok:16384                 #正确分配的槽位cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6                  #当前节点cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:48273cluster_stats_messages_pong_sent:49884cluster_stats_messages_sent:98157cluster_stats_messages_ping_received:49879cluster_stats_messages_pong_received:48273cluster_stats_messages_meet_received:5cluster_stats_messages_received:98157</code></pre><p><strong>3、查看节点状态</strong></p><p>使用<code>cluster nodes</code>命令查看节点状态。</p><pre class=" language-she"><code class="language-she">127.0.0.1:7000> cluster nodesbe2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002@17002 master - 0 1517303607000 3 connected 10923-1638313d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001@17001 master - 0 1517303606000 2 connected 5461-109223d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003@17003 slave 13d0c397604a0b2644244c37b666fce83f29faa8 0 1517303606030 4 connectedd5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000@17000 myself,master - 0 1517303604000 1 connected 0-546099c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005@17005 slave d5a834d075fd93eefab877c6ebb86efff680650f 0 1517303607060 6 connecteddedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004@17004 slave be2718476eba4e56f696e56b75e67df720b7fc24 0 1517303608082 5 connected</code></pre><p> 参考文章：</p><p><a href="https://redis.io/download" target="_blank" rel="noopener">https://redis.io/download</a></p><p><a href="https://redis.io/topics/cluster-tutorial" target="_blank" rel="noopener">https://redis.io/topics/cluster-tutorial</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Redis] Redis哨兵模式部署</title>
      <link href="/redis/redis-sentinel.html"/>
      <url>/redis/redis-sentinel.html</url>
      
        <content type="html"><![CDATA[<h2 id="1-部署Redis集群"><a href="#1-部署Redis集群" class="headerlink" title="1. 部署Redis集群"></a>1. 部署Redis集群</h2><p>redis的安装及配置参考[redis部署]</p><blockquote><p>本文以创建一主二从的集群为例。</p></blockquote><h3 id="1-1-部署与配置"><a href="#1-1-部署与配置" class="headerlink" title="1.1 部署与配置"></a>1.1 部署与配置</h3><p>先创建<code>sentinel</code>目录，在该目录下创建<code>8000</code>，<code>8001</code>，<code>8002</code>三个以端口号命名的目录。</p><pre class=" language-shell"><code class="language-shell">mkdir sentinelcd sentinelmkdir 8000 8001 8002 </code></pre><p>在对应端口号目录中创建<code>redis.conf</code>的文件，配置文件中的端口号<code>port</code>参数改为对应目录的端口号。配置如下：</p><pre class=" language-shell"><code class="language-shell"># 守护进程模式daemonize yes# pid filepidfile /var/run/redis.pid# 监听端口port 8000# TCP接收队列长度，受/proc/sys/net/core/somaxconn和tcp_max_syn_backlog这两个内核参数的影响tcp-backlog 511# 一个客户端空闲多少秒后关闭连接(0代表禁用，永不关闭)timeout 0# 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACKtcp-keepalive 60# 指定服务器调试等级# 可能值：# debug （大量信息，对开发/测试有用）# verbose （很多精简的有用信息，但是不像debug等级那么多）# notice （适量的信息，基本上是你生产环境中需要的）# warning （只有很重要/严重的信息会记录下来）loglevel notice# 指明日志文件名logfile "./redis8000.log"# 设置数据库个数databases 16# 会在指定秒数和数据变化次数之后把数据库写到磁盘上# 900秒（15分钟）之后，且至少1次变更# 300秒（5分钟）之后，且至少10次变更# 60秒之后，且至少10000次变更save 900 1save 300 10save 60 10000# 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作# 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难stop-writes-on-bgsave-error yes# 当导出到 .rdb 数据库时是否用LZF压缩字符串对象rdbcompression yes# 版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠。rdbchecksum yes# 持久化数据库的文件名dbfilename dump.rdb# 工作目录dir ./# 当master服务设置了密码保护时，slave服务连接master的密码masterauth 0234kz9*l# 当一个slave失去和master的连接，或者同步正在进行中，slave的行为可以有两种：## 1) 如果 slave-serve-stale-data 设置为 "yes" (默认值)，slave会继续响应客户端请求，# 可能是正常数据，或者是过时了的数据，也可能是还没获得值的空数据。# 2) 如果 slave-serve-stale-data 设置为 "no"，slave会回复"正在从master同步# （SYNC with master in progress）"来处理各种请求，除了 INFO 和 SLAVEOF 命令。slave-serve-stale-data yes# 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve# 的数据在同master同步之后将很容易被删除slave-read-only yes# 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY？# 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave# 上有延迟，Linux内核的默认配置会达到40毫秒# 如果你选择了 "no" 数据传输到salve的延迟将会减少但要使用更多的带宽repl-disable-tcp-nodelay no# slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，哨兵将用它来# 选择一个slave提升=升为master。# 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25，# 哨兵将挑选优先级最小数字为10的slave。# 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被# 哨兵挑选提升为masterslave-priority 100# 密码验证# 警告：因为Redis太快了，所以外面的人可以尝试每秒150k的密码来试图破解密码。这意味着你需要# 一个高强度的密码，否则破解太容易了requirepass 0234kz9*l# redis实例最大占用内存，不要用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见：# maxmemmory-policy）删除keymaxmemory 3gb# 最大内存策略：如果达到内存限制了，Redis如何选择删除key。你可以在下面五个行为里选：# volatile-lru -> 根据LRU算法删除带有过期时间的key。# allkeys-lru -> 根据LRU算法删除任何key。# volatile-random -> 根据过期设置来随机删除key, 具备过期时间的key。# allkeys->random -> 无差别随机删, 任何一个key。# volatile-ttl -> 根据最近过期时间来删除（辅以TTL）, 这是对于有过期时间的key# noeviction -> 谁也不删，直接在写操作时返回错误。maxmemory-policy volatile-lru# 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程# 出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。## AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置）# 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis# 能只丢失1秒的写操作。## AOF和RDB持久化能同时启动并且不会有问题。# 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。appendonly no# aof文件名appendfilename "appendonly.aof"# fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。# 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。## Redis支持三种不同的模式：## no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。# always：每次写操作都立刻写入到aof文件。慢，但是最安全。# everysec：每秒写一次。折中方案。appendfsync everysec# 如果AOF的同步策略设置成 "always" 或者 "everysec"，并且后台的存储进程（后台存储或写入AOF# 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。# 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。## 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止主进程进行fsync()。## 这就意味着如果有子进程在进行保存操作，那么Redis就处于"不可同步"的状态。# 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）## 如果你有延时问题把这个设置成"yes"，否则就保持"no"，这是保存持久数据的最安全的方式。no-appendfsync-on-rewrite yes# 自动重写AOF文件auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# AOF文件可能在尾部是不完整的（这跟system关闭有问题，尤其是mount ext4文件系统时# 没有加上data=ordered选项。只会发生在os死时，redis自己死不会不完整）。# 那redis重启时load进内存的时候就有问题了。# 发生的时候，可以选择redis启动报错，并且通知用户和写日志，或者load尽量多正常的数据。# 如果aof-load-truncated是yes，会自动发布一个log给客户端然后load（默认）。# 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。# 注意，如果在读取的过程中，发现这个aof是损坏的，服务器也是会退出的，# 这个选项仅仅用于当服务器尝试读取更多的数据但又找不到相应的数据时。aof-load-truncated yes# Lua 脚本的最大执行时间，毫秒为单位lua-time-limit 5000# Redis慢查询日志可以记录超过指定时间的查询slowlog-log-slower-than 10000# 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。slowlog-max-len 128# redis延时监控系统在运行时会采样一些操作，以便收集可能导致延时的数据根源。# 通过 LATENCY命令 可以打印一些图样和获取一些报告，方便监控# 这个系统仅仅记录那个执行时间大于或等于预定时间（毫秒）的操作,# 这个预定时间是通过latency-monitor-threshold配置来指定的，# 当设置为0时，这个监控系统处于停止状态latency-monitor-threshold 0# Redis能通知 Pub/Sub 客户端关于键空间发生的事件，默认关闭notify-keyspace-events ""# 当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限制时，会用一种节省内存的# 数据结构来编码。可以通过下面的指令来设定限制hash-max-ziplist-entries 512hash-max-ziplist-value 64# 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。# 这种特殊的方式只有在符合下面限制时才可以用list-max-ziplist-entries 512list-max-ziplist-value 64# set有一种特殊编码的情况：当set数据全是十进制64位有符号整型数字构成的字符串时。# 下面这个配置项就是用来设置set使用这种编码来节省内存的最大长度。set-max-intset-entries 512# 与hash和list相似，有序集合也可以用一种特别的编码方式来节省大量空间。# 这种编码只适合长度和元素都小于下面限制的有序集合zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog稀疏结构表示字节的限制。该限制包括# 16个字节的头。当HyperLogLog使用稀疏结构表示# 这些限制，它会被转换成密度表示。# 值大于16000是完全没用的，因为在该点# 密集的表示是更多的内存效率。# 建议值是3000左右，以便具有的内存好处, 减少内存的消耗hll-sparse-max-bytes 3000# 启用哈希刷新，每100个CPU毫秒会拿出1个毫秒来刷新Redis的主哈希表（顶级键值映射表）activerehashing yes# 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# 默认情况下，“hz”的被设定为10。提高该值将在Redis空闲时使用更多的CPU时，但同时当有多个key# 同时到期会使Redis的反应更灵敏，以及超时可以更精确地处理hz 10# 当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步aof-rewrite-incremental-fsync yes</code></pre><h3 id="1-2-配置主从关系"><a href="#1-2-配置主从关系" class="headerlink" title="1.2 配置主从关系"></a>1.2 配置主从关系</h3><p><strong>1、启动实例</strong></p><p>三个Redis实例配置相同，分别启动三个Redis实例。建议将<code>redis-server</code>、<code>redis-cli</code>、<code>redis-sentinel</code>的二进制复制到<code>/usr/local/bin</code>的目录下。</p><pre class=" language-shell"><code class="language-shell">cd 8000redis-server redis.conf</code></pre><p><strong>2、配置主从关系</strong></p><p>例如，将8000端口实例设为主，8001和8002端口的实例设为从。</p><p>则分别登录8001和8002的实例，执行<code>slaveof &lt;MASTER_IP&gt; &lt;MASTER_PORT&gt;</code>命令。</p><p>例如：</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 8000]# redis-cli -c -p 8001 -a 0234kz9*l127.0.0.1:8001> slaveof 127.0.0.1 8000OK</code></pre><p><strong>3、检查集群状态</strong></p><p>登录master和slave实例，执行<code>info replication</code>查看集群状态。</p><p>Master</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 8000]# redis-cli -c -p 8000 -a 0234kz9*l127.0.0.1:8000> info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=8001,state=online,offset=2853,lag=0slave1:ip=127.0.0.1,port=8002,state=online,offset=2853,lag=0master_replid:4f8331d5f180a4669241ab0dd97e43508abd6d8fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:2853second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:2853</code></pre><p>Slave</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 8000]# redis-cli -c -p 8001 -a 0234kz9*l127.0.0.1:8001> info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:8000master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_repl_offset:2909slave_priority:100slave_read_only:1connected_slaves:0master_replid:4f8331d5f180a4669241ab0dd97e43508abd6d8fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:2909second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:2909</code></pre><p>也可以往master写数据，从slave读取数据来验证。</p><h2 id="2-部署sentinel集群"><a href="#2-部署sentinel集群" class="headerlink" title="2. 部署sentinel集群"></a>2. 部署sentinel集群</h2><h3 id="2-1-部署与配置"><a href="#2-1-部署与配置" class="headerlink" title="2.1 部署与配置"></a>2.1 部署与配置</h3><p>在之前创建的<code>sentinel</code>目录中场景sentinel端口号命名的目录<code>28000</code>，<code>28001</code>，<code>28002</code>。</p><pre class=" language-shell"><code class="language-shell">cd sentinelmkdir 28000 28001 28002 </code></pre><p>在对应端口号目录中创建<code>redis.conf</code>的文件，配置文件中的端口号<code>port</code>参数改为对应目录的端口号。配置如下：</p><pre class=" language-shell"><code class="language-shell">port 28000sentinel monitor mymaster 127.0.0.1 8000 2sentinel down-after-milliseconds mymaster 60000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1</code></pre><h3 id="2-2-启动sentinel实例"><a href="#2-2-启动sentinel实例" class="headerlink" title="2.2 启动sentinel实例"></a>2.2 启动sentinel实例</h3><pre class=" language-shell"><code class="language-shell">#& 表示后台运行的方式redis-sentinel sentinel.conf &</code></pre><h3 id="2-3-查看状态"><a href="#2-3-查看状态" class="headerlink" title="2.3 查看状态"></a>2.3 查看状态</h3><p>使用<code>sentinel masters</code>命令查看监控的master节点。</p><pre class=" language-shell"><code class="language-shell">[root@kube-node-1 28000]# redis-cli -c -p 28000 -a 0234kz9*l127.0.0.1:28000>127.0.0.1:28000> pingPONG127.0.0.1:28000>127.0.0.1:28000> sentinel masters1)  1) "name"    2) "mymaster"    3) "ip"    4) "127.0.0.1"    5) "port"    6) "8000"    7) "runid"    8) ""    9) "flags"   10) "s_down,master,disconnected"   11) "link-pending-commands"   12) "0"   13) "link-refcount"   14) "1"   15) "last-ping-sent"   16) "187539"   17) "last-ok-ping-reply"   18) "187539"   19) "last-ping-reply"   20) "3943"   21) "s-down-time"   22) "127491"   23) "down-after-milliseconds"   24) "60000"   25) "info-refresh"   26) "1517346914642"   27) "role-reported"   28) "master"   29) "role-reported-time"   30) "187539"   31) "config-epoch"   32) "0"   33) "num-slaves"   34) "0"   35) "num-other-sentinels"   36) "0"   37) "quorum"   38) "2"   39) "failover-timeout"   40) "180000"   41) "parallel-syncs"   42) "1"</code></pre><p>参考文章：</p><p><a href="https://redis.io/topics/sentinel" target="_blank" rel="noopener">https://redis.io/topics/sentinel</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Database] Mysql常用命令</title>
      <link href="/hello-world.html"/>
      <url>/hello-world.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Database] Mysql常用命令</title>
      <link href="/database/mysql-commonds.html"/>
      <url>/database/mysql-commonds.html</url>
      
        <content type="html"><![CDATA[<h2 id="1-系统管理"><a href="#1-系统管理" class="headerlink" title="1. 系统管理"></a>1. 系统管理</h2><h3 id="1-1-连接mysql"><a href="#1-1-连接mysql" class="headerlink" title="1.1. 连接mysql"></a>1.1. 连接mysql</h3><p>格式： mysql -h主机地址 -u用户名 －p用户密码</p><p>连接本地：mysql -h<code>localhost/127.0.0.1</code> -u用户名 －p用户密码</p><p>连接远程：mysql -h<code>主机地址</code> -u用户名 －p用户密码<br>退出连接：exit</p><h3 id="1-2-备份数据库"><a href="#1-2-备份数据库" class="headerlink" title="1.2. 备份数据库"></a>1.2. 备份数据库</h3><p><strong>1.导出整个数据库</strong></p><p>导出文件默认是存在mysql\bin目录下</p><p>mysqldump -u 用户名 -p 数据库名 ` 导出的文件名</p><p>mysqldump -u user_name -p123456 database_name ` outfile_name.sql</p><p><strong>2.导出一个表</strong></p><p>mysqldump -u 用户名 -p 数据库名 表名` 导出的文件名</p><p>mysqldump -u user_name -p database_name table_name ` outfile_name.sql</p><p><strong>3.导出一个数据库结构</strong></p><p>mysqldump -u user_name -p -d –add-drop-table database_name ` outfile_name.sql</p><p>-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table</p><p><strong>4.带语言参数导出</strong></p><p>mysqldump -uroot -p –default-character-set=latin1 –set-charset=gbk –skip-opt database_name ` outfile_name.sql</p><p><strong>5、导入数据库</strong></p><p>mysql -u root –p ` [备份文件的保存路径] 或者source [备份文件的保存路径]</p><h3 id="1-3-用户管理"><a href="#1-3-用户管理" class="headerlink" title="1.3. 用户管理"></a>1.3. 用户管理</h3><p><strong>1、创建用户</strong></p><p>​    create user ‘用户名‘@’IP地址’ identified by ‘密码’;</p><p><strong>2、删除用户</strong></p><p>​    drop user ‘用户名‘@’IP地址’;</p><p>​    delete from user where user=’用户名’ and host=’localhost’;</p><p><strong>3、修改用户</strong></p><p>​    rename user ‘用户名‘@’IP地址’; to ‘新用户名‘@’IP地址’;;</p><p><strong>4、修改密码</strong></p><p>​    set password for ‘用户名‘@’IP地址’ = Password(‘新密码’)</p><p>​    mysqladmin -u用户名 -p旧密码 password 新密码</p><h3 id="1-4-权限管理"><a href="#1-4-权限管理" class="headerlink" title="1.4. 权限管理"></a>1.4. 权限管理</h3><h4 id="1-4-1-grant"><a href="#1-4-1-grant" class="headerlink" title="1.4.1. grant"></a>1.4.1. grant</h4><p><strong>1、grant 权限 on 数据库对象 to 用户</strong></p><p>数据库对象的格式为<code>database</code>.<code>table</code>。<code>database</code>.<em>：表示授权数据库对象该数据库的所有表；</em>.*：表示授权数据库对象为所有数据库的所有表。</p><p>grant all privileges on <em>.</em> to <code>user</code>@’<code>ip</code>‘ identified by ‘<code>passwd</code>‘;如果<code>ip</code>为’%’表示不限制IP。</p><p><strong>2、撤销权限</strong>：</p><p>revoke all on <em>.</em> from <code>user</code>@<code>ip</code>; </p><h4 id="1-4-2-普通数据库用户"><a href="#1-4-2-普通数据库用户" class="headerlink" title="1.4.2. 普通数据库用户"></a>1.4.2. 普通数据库用户</h4><p>查询、插入、更新、删除 数据库中所有表数据的权利</p><p>grant select, insert, update, delete on testdb.* to <code>user</code>@’<code>ip</code>‘;</p><h4 id="1-4-3-DBA-用户"><a href="#1-4-3-DBA-用户" class="headerlink" title="1.4.3. DBA 用户"></a>1.4.3. DBA 用户</h4><p><strong>1、授权</strong></p><p>grant all privileges on <em>.</em> to <code>dba</code>@’<code>ip</code>‘ identified by ‘<code>passwd</code>‘;</p><p><strong>2、刷新系统权限</strong></p><p>flush privileges;</p><h4 id="1-4-4-查看用户权限"><a href="#1-4-4-查看用户权限" class="headerlink" title="1.4.4. 查看用户权限"></a>1.4.4. 查看用户权限</h4><p>1、查看当前用户（自己）权限</p><p>show grants;</p><p>2、查看指定MySQL 用户权限</p><p>show grants for <code>user</code>@<code>localhost</code>;</p><p>3、查看user和host</p><p>select user,host from mysql.user order by user;</p><h4 id="1-4-5-权限列表"><a href="#1-4-5-权限列表" class="headerlink" title="1.4.5. 权限列表"></a>1.4.5. 权限列表</h4><p><img src="https://res.cloudinary.com/dqxtn0ick/image/upload/v1510578472/article/database/permission.jpg" alt="img"></p><h4 id="1-4-6-查看主从关系"><a href="#1-4-6-查看主从关系" class="headerlink" title="1.4.6. 查看主从关系"></a>1.4.6. 查看主从关系</h4><p>登录主机：show slave hosts;</p><p>登录从机：show slave status;</p><h2 id="2-数据库操作"><a href="#2-数据库操作" class="headerlink" title="2. 数据库操作"></a>2. 数据库操作</h2><p><strong>1、创建数据库</strong></p><p>create database <code>数据库名</code></p><p><strong>2、显示数据库</strong></p><p>show databases</p><p><strong>3、删除数据</strong></p><p>drop database <code>数据库名</code></p><h2 id="3-数据表操作"><a href="#3-数据表操作" class="headerlink" title="3. 数据表操作"></a>3. 数据表操作</h2><p><strong>1、创建表</strong></p><blockquote><p>create table 表名(</p><p>​    列名  类型  是否可以为空，</p><p>​    列名  类型  是否可以为空</p><p>)ENGINE=InnoDB DEFAULT CHARSET=utf8</p></blockquote><ul><li>默认值，创建列时可以指定默认值，当插入数据时如果未主动设置，则自动添加默认值</li><li>自增，如果为某列设置自增列，插入数据时无需设置此列，默认将自增（表中只能有一个自增列）注意：1、对于自增列，必须是索引（含主键）2、对于自增可以设置步长和起始值</li><li>主键，一种特殊的唯一索引，不允许有空值，如果主键使用单个列，则它的值必须唯一，如果是多列，则其组合必须唯一。</li></ul><p><strong>2、查看表</strong></p><p>show tables;                    # 查看数据库全部表</p><p>select * from 表名;             # 查看表所有内容</p><p><strong>3、删除表</strong></p><p>drop table 表名</p><p><strong>4、清空表内容</strong></p><p>delete from 表名</p><p>truncate table 表名</p><p><strong>5、查看表结构</strong></p><p>desc 表名</p><p><strong>6、修改表</strong></p><blockquote><p>添加列：   alter table 表名 add 列名 类型</p><p>删除列：   alter table 表名 drop column 列名</p><p>修改列：</p><p>​          alter table 表名 modify column 列名 类型;  – 类型</p><p>​          alter table 表名 change 原列名 新列名 类型; – 列名，类型</p><p>添加主键：</p><p>​          alter table 表名 add primary key(列名);</p><p>删除主键：</p><p>​          alter table 表名 drop primary key;</p><p>​          alter table 表名  modify  列名 int, drop primary key;</p><p>添加外键： alter table 从表 add constraint 外键名称（形如：FK_从表_主表） foreign key 从表(外键字段) references 主表(主键字段);</p><p>删除外键： alter table 表名 drop foreign key 外键名称</p><p>修改默认值：ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000;</p><p>删除默认值：ALTER TABLE testalter_tbl ALTER i DROP DEFAULT;</p></blockquote><h2 id="4-表内容操作"><a href="#4-表内容操作" class="headerlink" title="4. 表内容操作"></a>4. 表内容操作</h2><h3 id="4-1-增"><a href="#4-1-增" class="headerlink" title="4.1. 增"></a>4.1. 增</h3><blockquote><p>insert into 表 (列名,列名…) values (值,值,…)</p><p>insert into 表 (列名,列名…) values (值,值,…),(值,值,值…)</p><p>insert into 表 (列名,列名…) select (列名,列名…) from 表</p><p>例：</p><p>​    insert into tab1(name,email) values(‘zhangyanlin’,‘zhangyanlin8851@<a href="http://163.com/" target="_blank" rel="noopener">163.com</a>‘)</p></blockquote><h3 id="4-2-删"><a href="#4-2-删" class="headerlink" title="4.2. 删"></a>4.2. 删</h3><blockquote><p>delete from 表                                      # 删除表里全部数据</p><p>delete from 表 where id＝1 and name＝’zhangyanlin’   # 删除ID =1 和name=’zhangyanlin’ 那一行数据</p></blockquote><h3 id="4-3-改"><a href="#4-3-改" class="headerlink" title="4.3. 改"></a>4.3. 改</h3><blockquote><p>update 表 set name ＝ ‘zhangyanlin’ where id`1</p></blockquote><h3 id="4-4-查"><a href="#4-4-查" class="headerlink" title="4.4. 查"></a>4.4. 查</h3><blockquote><p>select * from 表</p><p>select * from 表 where id ` 1</p><p>select nid,name,gender as gg from 表 where id ` 1</p></blockquote><h3 id="4-5-条件判断"><a href="#4-5-条件判断" class="headerlink" title="4.5. 条件判断"></a>4.5. 条件判断</h3><h4 id="4-5-1-where"><a href="#4-5-1-where" class="headerlink" title="4.5.1. where"></a>4.5.1. where</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> where id <span class="token string">`1 and name!='huwh' and num =12;select * from `</span>table<span class="token string">` where id between 5 and 6;select * from `</span>table<span class="token string">` where id in (11,22,33);select * from `</span>table<span class="token string">` where id not in (11,22,33);select * from `</span>table<span class="token string">` where id in (select nid from `</span>table`<span class="token punctuation">)</span></code></pre><h4 id="4-5-2-通配符like"><a href="#4-5-2-通配符like" class="headerlink" title="4.5.2. 通配符like"></a>4.5.2. 通配符like</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> where name like <span class="token string">'hu%'</span><span class="token punctuation">;</span>   #hu开头<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> where name like <span class="token string">'hu_'</span>    #hu开头后接一个字符</code></pre><h4 id="4-5-3-限制limit"><a href="#4-5-3-限制limit" class="headerlink" title="4.5.3. 限制limit"></a>4.5.3. 限制limit</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> limit <span class="token number">5</span><span class="token punctuation">;</span>   #前<span class="token number">5</span>行<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> limit <span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span>  #从第四行开始的<span class="token number">5</span>行<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> limit <span class="token number">5</span> offset <span class="token number">4</span><span class="token punctuation">;</span>#从第四行开始的<span class="token number">5</span>行</code></pre><h4 id="4-5-4-排序asc，desc"><a href="#4-5-4-排序asc，desc" class="headerlink" title="4.5.4. 排序asc，desc"></a>4.5.4. 排序asc，desc</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> order by 列 asc<span class="token punctuation">;</span>            #跟据“列”从小到大排序（不指定默认为从小到大排序）<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> order by 列 desc<span class="token punctuation">;</span>           #根据“列”从大到小排序<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> order by 列<span class="token number">1</span> desc<span class="token punctuation">,</span>列<span class="token number">2</span> asc<span class="token punctuation">;</span>  #根据“列<span class="token number">1</span>”从大到小排序，如果相同则按“列<span class="token number">2</span>”从小到大排序</code></pre><h4 id="4-5-5-分组group-by"><a href="#4-5-5-分组group-by" class="headerlink" title="4.5.5. 分组group by"></a>4.5.5. 分组group by</h4><p>group by 必须在where之后，order by之前。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> num<span class="token punctuation">,</span>from <span class="token string">`table`</span> group by num<span class="token punctuation">;</span>     <span class="token keyword">select</span> num<span class="token punctuation">,</span>nid from <span class="token string">`table`</span> group by num<span class="token punctuation">,</span>nid<span class="token punctuation">;</span><span class="token keyword">select</span> num from <span class="token string">`table`</span> where nid <span class="token string">` 10 group by num,nid order nid desc;select num,nid,count(*),sum(score),max(score) from `</span>table<span class="token string">` group by num;select num from `</span>table<span class="token string">` group by num having max(id) `</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">select</span> num from <span class="token string">`table`</span> group by num<span class="token punctuation">;</span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Database </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
