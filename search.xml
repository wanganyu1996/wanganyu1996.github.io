<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>如何解决消息队列的延时以及过期失效问题？</title>
      <link href="/mq-knowledge/mq-time-delay-and-expired-failure.html"/>
      <url>/mq-knowledge/mq-time-delay-and-expired-failure.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？</p><p>所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在 mq 里积压，现在出事故了，慌了。</p><h3 id="大量消息在-mq-里积压了几个小时了还没解决"><a href="#大量消息在-mq-里积压了几个小时了还没解决" class="headerlink" title="大量消息在 mq 里积压了几个小时了还没解决"></a>大量消息在 mq 里积压了几个小时了还没解决</h3><p>几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。</p><p>一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。</p><p>一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：</p><ul><li>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。</li><li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。</li><li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</li><li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li><li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息。</li></ul><h3 id="mq-中的消息过期失效了"><a href="#mq-中的消息过期失效了" class="headerlink" title="mq 中的消息过期失效了"></a>mq 中的消息过期失效了</h3><p>假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是<strong>大量的数据会直接搞丢</strong>。</p><p>这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是<strong>批量重导</strong>，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。</p><p>假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。</p><h3 id="mq-都快写满了"><a href="#mq-都快写满了" class="headerlink" title="mq 都快写满了"></a>mq 都快写满了</h3><p>如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，<strong>消费一个丢弃一个，都不要了</strong>，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何保证消息的顺序性？</title>
      <link href="/mq-knowledge/how-to-ensure-the-order-of-messages.html"/>
      <url>/mq-knowledge/how-to-ensure-the-order-of-messages.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息的顺序性？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这个也是用 MQ 的时候必问的话题，第一看看你了不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这是生产系统中常见的问题。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>我举个例子，我们以前做过一个 mysql <code>binlog</code> 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -&gt; mysql）。常见的一点在于说比如大数据 team，就需要同步一个 mysql 库过来，对公司的业务系统的数据做各种复杂的操作。</p><p>你在 mysql 里增删改一条数据，对应出来了增删改 3 条 <code>binlog</code> 日志，接着这三条 <code>binlog</code> 发送到 MQ 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p><p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p><p>先看看顺序会错乱的俩场景：</p><ul><li><strong>RabbitMQ</strong>：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。</li></ul><p><img src="/images/rabbitmq-order-01.png" alt="rabbitmq-order-01"></p><ul><li><strong>Kafka</strong>：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。<br>消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞<strong>多个线程来并发处理消息</strong>。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。</li></ul><p><img src="/images/kafka-order-01.png" alt="kafka-order-01"></p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。<br><img src="/images/rabbitmq-order-02.png" alt="rabbitmq-order-02"></p><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><ul><li>一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。</li><li>写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</li></ul><p><img src="/images/kafka-order-02.png" alt="kafka-order-02"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何保证消息不被重复消费</title>
      <link href="/mq-knowledge/how-to-ensure-that-messages-are-not-repeatedly-consumed.html"/>
      <url>/mq-knowledge/how-to-ensure-that-messages-are-not-repeatedly-consumed.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是很常见的一个问题，这俩问题基本可以连起来问。既然是消费消息，那肯定要考虑会不会重复消费？能不能避免重复消费？或者重复消费了也别造成系统异常可以吗？这个是 MQ 领域的基本问题，其实本质上还是问你<strong>使用消息队列如何保证幂等性</strong>，这个是你架构里要考虑的一个问题。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>回答这个问题，首先你别听到重复消息这个事儿，就一无所知吧，你<strong>先大概说一说可能会有哪些重复消费的问题</strong>。</p><p>首先，比如 RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 MQ 自己保证的，是由我们开发来保证的。挑一个 Kafka 来举个例子，说说怎么重复消费吧。</p><p>Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，<strong>每隔一段时间</strong>（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。</p><p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。</p><p>举个栗子。</p><p>有这么个场景。数据 1/2/3 依次进入 kafka，kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 <code>offset=153</code> 的这条数据，刚准备去提交 offset 到 zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，kafka 也就不知道你已经消费了 <code>offset=153</code> 这条数据。那么重启之后，消费者会找 kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。</p><p><img src="/images/mq-10.png" alt="mq-10"></p><p>如果消费者干的事儿是拿一条数据就往数据库里写一条，会导致说，你可能就把数据 1/2 在数据库里插入了 2 次，那么数据就错啦。</p><p>其实重复消费不可怕，可怕的是你没考虑到重复消费之后，<strong>怎么保证幂等性</strong>。</p><p>举个例子吧。假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。</p><p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。</p><p>幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，<strong>不能出错</strong>。</p><p>所以第二个问题来了，怎么保证消息队列消费的幂等性？</p><p>其实还是得结合业务来思考，我这里给几个思路：</p><ul><li>比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。</li><li>比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。</li><li>比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</li><li>比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。</li></ul><p><img src="/images/mq-11.png" alt="mq-11"></p><p>当然，如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何保证消息的可靠性传输？</title>
      <link href="/mq-knowledge/how-to-ensure-the-reliable-transmission-of-messages.html"/>
      <url>/mq-knowledge/how-to-ensure-the-reliable-transmission-of-messages.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个是肯定的，用 MQ 有个基本原则，就是<strong>数据不能多一条，也不能少一条</strong>，不能多，就是前面说的<a href="/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md">重复消费和幂等性问题</a>。不能少，就是说这数据别搞丢了。那这个问题你必须得考虑一下。</p><p>如果说你这个是用 MQ 来传递非常核心的消息，比如说计费、扣费的一些消息，那必须确保这个 MQ 传递过程中<strong>绝对不会把计费消息给弄丢</strong>。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>数据的丢失问题，可能出现在生产者、MQ、消费者中，咱们从 RabbitMQ 和 Kafka 分别来分析一下吧。</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p><img src="/images/rabbitmq-message-lose.png" alt="rabbitmq-message-lose"></p><h4 id="生产者弄丢了数据"><a href="#生产者弄丢了数据" class="headerlink" title="生产者弄丢了数据"></a>生产者弄丢了数据</h4><p>生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。</p><p>此时可以选择用 RabbitMQ 提供的事务功能，就是生产者<strong>发送数据之前</strong>开启 RabbitMQ 事务<code>channel.txSelect</code>，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务<code>channel.txRollback</code>，然后重试发送消息；如果收到了消息，那么可以提交事务<code>channel.txCommit</code>。</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 开启事务</span>channel<span class="token punctuation">.</span>txSelect<span class="token keyword">try</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 这里发送消息</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>    channel<span class="token punctuation">.</span>txRollback    <span class="token comment" spellcheck="true">// 这里再次重发这条消息</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 提交事务</span>channel<span class="token punctuation">.</span>txCommit</code></pre><p>但是问题是，RabbitMQ 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p><p>所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 <code>confirm</code> 模式，在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>事务机制和 <code>cnofirm</code> 机制最大的不同在于，<strong>事务机制是同步的</strong>，你提交一个事务之后会<strong>阻塞</strong>在那儿，但是 <code>confirm</code> 机制是<strong>异步</strong>的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。</p><p>所以一般在生产者这块<strong>避免数据丢失</strong>，都是用 <code>confirm</code> 机制的。</p><h4 id="RabbitMQ-弄丢了数据"><a href="#RabbitMQ-弄丢了数据" class="headerlink" title="RabbitMQ 弄丢了数据"></a>RabbitMQ 弄丢了数据</h4><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p><p>设置持久化有<strong>两个步骤</strong>：</p><ul><li>创建 queue 的时候将其设置为持久化<br><br>这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。</li><li>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2<br><br>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li></ul><p>必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 <code>confirm</code> 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 <code>ack</code> 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 <code>ack</code>，你也是可以自己重发的。</p><h4 id="消费端弄丢了数据"><a href="#消费端弄丢了数据" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><p>RabbitMQ 如果丢失了数据，主要是因为你消费的时候，<strong>刚消费到，还没处理，结果进程挂了</strong>，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</p><p>这个时候得用 RabbitMQ 提供的 <code>ack</code> 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 <code>ack</code>，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 <code>ack</code> 一把。这样的话，如果你还没处理完，不就没有 <code>ack</code> 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。</p><p><img src="/images/rabbitmq-message-lose-solution.png" alt="rabbitmq-message-lose-solution"></p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h4 id="消费端弄丢了数据-1"><a href="#消费端弄丢了数据-1" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><p>唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边<strong>自动提交了 offset</strong>，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p><p>这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要<strong>关闭自动提交</strong> offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是<strong>可能会有重复消费</strong>，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p><p>生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。</p><h4 id="Kafka-弄丢了数据"><a href="#Kafka-弄丢了数据" class="headerlink" title="Kafka 弄丢了数据"></a>Kafka 弄丢了数据</h4><p>这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。</p><p>生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。</p><p>所以此时一般是要求起码设置如下 4 个参数：</p><ul><li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</li><li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</li><li>在 producer 端设置 <code>acks=all</code>：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</li><li>在 producer 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li></ul><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p><h4 id="生产者会不会弄丢数据？"><a href="#生产者会不会弄丢数据？" class="headerlink" title="生产者会不会弄丢数据？"></a>生产者会不会弄丢数据？</h4><p>如果按照上述的思路设置了 <code>acks=all</code>，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么使用消息队列</title>
      <link href="/mq-knowledge/why-mq.html"/>
      <url>/mq-knowledge/why-mq.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><ul><li>为什么使用消息队列？</li><li>消息队列有什么优点和缺点？</li><li>Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？</li></ul><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实面试官主要是想看看：</p><ul><li><p><strong>第一</strong>，你知不知道你们系统里为什么要用消息队列这个东西？<br><br>不少候选人，说自己项目里用了 Redis、MQ，但是其实他并不知道自己为什么要用这个东西。其实说白了，就是为了用而用，或者是别人设计的架构，他从头到尾都没思考过。<br><br>没有对自己的架构问过为什么的人，一定是平时没有思考的人，面试官对这类候选人印象通常很不好。因为面试官担心你进了团队之后只会木头木脑的干呆活儿，不会自己思考。</p></li><li><p><strong>第二</strong>，你既然用了消息队列这个东西，你知不知道用了有什么好处&amp;坏处？<br><br>你要是没考虑过这个，那你盲目弄个 MQ 进系统里，后面出了问题你是不是就自己溜了给公司留坑？你要是没考虑过引入一个技术可能存在的弊端和风险，面试官把这类候选人招进来了，基本可能就是挖坑型选手。就怕你干 1 年挖一堆坑，自己跳槽了，给公司留下无穷后患。</p></li><li><p><strong>第三</strong>，既然你用了 MQ，可能是某一种 MQ，那么你当时做没做过调研？<br><br>你别傻乎乎的自己拍脑袋看个人喜好就瞎用了一个 MQ，比如 Kafka，甚至都从没调研过业界流行的 MQ 到底有哪几种。每一个 MQ 的优点和缺点是什么。每一个 MQ <strong>没有绝对的好坏</strong>，但是就是看用在哪个场景可以<strong>扬长避短，利用其优势，规避其劣势</strong>。<br><br>如果是一个不考虑技术选型的候选人招进了团队，leader 交给他一个任务，去设计个什么系统，他在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑。</p></li></ul><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么使用消息队列"><a href="#为什么使用消息队列" class="headerlink" title="为什么使用消息队列"></a>为什么使用消息队列</h3><p>其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？</p><p>面试官问你这个问题，<strong>期望的一个回答</strong>是说，你们公司有个什么<strong>业务场景</strong>，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。</p><p>先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p><h4 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h4><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃……</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454712/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-1.png" alt="img"></p><p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454743/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-2.png" alt="img"></p><p><strong>总结</strong>：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。</p><p><strong>面试技巧</strong>：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454744/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-3.png" alt="img"></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。</p><p>如果<strong>使用 MQ</strong>，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454744/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-4.png" alt="img"></p><h4 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h4><p>每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p><p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454745/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-5.png" alt="img"></p><p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544454745/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/mq-6.png" alt="img"></p><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。</p><h3 id="消息队列有什么优缺点"><a href="#消息队列有什么优缺点" class="headerlink" title="消息队列有什么优缺点"></a>消息队列有什么优缺点</h3><p>优点上面已经说了，就是<strong>在特殊场景下有其对应的好处</strong>，<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p><p>缺点有以下几个：</p><ul><li><p>系统可用性降低<br><br>系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以<a href="/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md">点击这里查看</a>。</p></li><li><p>系统复杂度提高<br><br>硬生生加个 MQ 进来，你怎么<a href="/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md">保证消息没有重复消费</a>？怎么<a href="/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md">处理消息丢失的情况</a>？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p></li><li><p>一致性问题<br><br>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p></li></ul><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。</p><h3 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？"><a href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？" class="headerlink" title="Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？"></a>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</h3><table><thead><tr><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>同 ActiveMQ</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr><tr><td>topic 数量对吞吐量的影响</td><td></td><td></td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td></td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr><tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr></tbody></table><p>综上，各种对比之后，有如下建议：</p><p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；</p><p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</p><p>不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。</p><p>所以<strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p><p>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper介绍</title>
      <link href="/distributed-system/zookeeper-application-scenarios.html"/>
      <url>/distributed-system/zookeeper-application-scenarios.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>zookeeper 都有哪些使用场景？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>现在聊的 topic 是分布式系统，面试官跟你聊完了 dubbo 相关的一些问题之后，已经确认你对分布式服务框架/RPC框架基本都有一些认知了。那么他可能开始要跟你聊分布式相关的其它问题了。</p><p>分布式锁这个东西，很常用的，你做 Java系统开发，分布式系统，可能会有一些场景会用到。最常用的分布式锁就是基于 zookeeper 来实现的。</p><p>其实说实话，问这个问题，一般就是看看你是否了解 zookeeper，因为 zk 是分布式系统中很常见的一个基础系统。而且问的话常问的就是说 zk 的使用场景是什么？看你知道不知道一些基本的使用场景。但是其实 zk 挖深了自然是可以问的很深很深的。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>大致来说，zk 的使用场景如下，我就举几个简单的，大家能说几个就好了：</p><ul><li>分布式协调</li><li>分布式锁</li><li>元数据/配置信息管理</li><li>HA高可用性</li></ul><h3 id="分布式协调"><a href="#分布式协调" class="headerlink" title="分布式协调"></a>分布式协调</h3><p>这个其实是 zk 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zk 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zk 上<strong>对某个节点的值注册个监听器</strong>，一旦 B 系统处理完了就修改 zk 那个节点的值，A 立马就可以收到通知，完美解决。</p><p>  <img src="https://res.cloudinary.com/dijk2pkfa/image/upload/v1544358082/zookeeper-distributed-coordination.png"></p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zk 分布式锁，一个机器接收到了请求之后先获取 zk 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也<strong>尝试去创建</strong>那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。</p><p><img src="/img/zookeeper-distributed-lock-demo.png" alt="zookeeper-distributed-lock-demo"></p><h3 id="元数据-配置信息管理"><a href="#元数据-配置信息管理" class="headerlink" title="元数据/配置信息管理"></a>元数据/配置信息管理</h3><p>zk 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zk 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zk 么？</p><p><img src="/img/zookeeper-meta-data-manage.png" alt="zookeeper-meta-data-manage"></p><h3 id="HA高可用性"><a href="#HA高可用性" class="headerlink" title="HA高可用性"></a>HA高可用性</h3><p>这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zk 来开发 HA 高可用机制，就是一个<strong>重要进程一般会做主备</strong>两个，主进程挂了立马通过 zk 感知到切换到备用进程。</p><p><img src="/img/zookeeper-active-standby.png" alt="zookeeper-active-standby"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何保证消息队列的高可用？</title>
      <link href="/mq-knowledge/how-to-ensure-high-availability-of-message-queues.html"/>
      <url>/mq-knowledge/how-to-ensure-high-availability-of-message-queues.html</url>
      
        <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息队列的高可用？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>如果有人问到你 MQ 的知识，<strong>高可用是必问的</strong>。<a href="/docs/high-concurrency/why-mq.md">上一讲</a>提到，MQ 会导致<strong>系统可用性降低</strong>。所以只要你用了 MQ，接下来问的一些要点肯定就是围绕着 MQ 的那些缺点怎么来解决了。</p><p>要是你傻乎乎的就干用了一个 MQ，各种问题从来没考虑过，那你就杯具了，面试官对你的印象就是，只会简单使用一些技术，没任何思考，马上对你的印象就不太好了。这样的同学招进来要是做个 20k 薪资以内的普通小弟还凑合，要是做薪资 20k+ 的高工，那就惨了，让你设计个系统，里面肯定一堆坑，出了事故公司受损失，团队一起背锅。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个问题这么问是很好的，因为不能问你 Kafka 的高可用性怎么保证？ActiveMQ 的高可用性怎么保证？一个面试官要是这么问就显得很没水平，人家可能用的就是 RabbitMQ，没用过 Kafka，你上来问人家 Kafka 干什么？这不是摆明了刁难人么。</p><p>所以有水平的面试官，问的是 MQ 的高可用性怎么保证？这样就是你用过哪个 MQ，你就说说你对那个 MQ 的高可用性的理解。</p><h3 id="RabbitMQ-的高可用性"><a href="#RabbitMQ-的高可用性" class="headerlink" title="RabbitMQ 的高可用性"></a>RabbitMQ 的高可用性</h3><p>RabbitMQ 是比较有代表性的，因为是<strong>基于主从</strong>（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。</p><p>RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</p><h4 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h4><p>单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的😄，没人生产用单机模式。</p><h4 id="普通集群模式（无高可用性）"><a href="#普通集群模式（无高可用性）" class="headerlink" title="普通集群模式（无高可用性）"></a>普通集群模式（无高可用性）</h4><p>普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。但是你<strong>创建的 queue，只会放在一个 RabbitMQ 实例上</strong>，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。</p><p><img src="/img/mq-7.png" alt="mq-7"></p><p>这种方式确实很麻烦，也不怎么好，<strong>没做到所谓的分布式</strong>，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有<strong>数据拉取的开销</strong>，后者导致<strong>单实例性能瓶颈</strong>。</p><p>而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你<strong>开启了消息持久化</strong>，让 RabbitMQ 落地存储消息的话，<strong>消息不一定会丢</strong>，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。</p><p>所以这个事儿就比较尴尬了，这就<strong>没有什么所谓的高可用性</strong>，<strong>这方案主要是提高吞吐量的</strong>，就是说让集群中多个节点来服务某个 queue 的读写操作。</p><h4 id="镜像集群模式（高可用性）"><a href="#镜像集群模式（高可用性）" class="headerlink" title="镜像集群模式（高可用性）"></a>镜像集群模式（高可用性）</h4><p>这种模式，才是所谓的 RabbitMQ 的高可用模式，跟普通集群模式不一样的是，你创建的 queue，无论元数据还是 queue 里的消息都会<strong>存在于多个实例上</strong>，然后每次你写消息到 queue 的时候，都会自动把<strong>消息同步</strong>到多个实例的 queue 上。</p><p><img src="/img/mq-8.png" alt="mq-8"></p><p>这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就<strong>没有扩展性可言</strong>了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。</p><p>那么<strong>如何开启这个镜像集群模式</strong>呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是<strong>镜像集群模式的策略</strong>，指定的时候可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p><h3 id="Kafka-的高可用性"><a href="#Kafka-的高可用性" class="headerlink" title="Kafka 的高可用性"></a>Kafka 的高可用性</h3><p>Kafka 一个最基本的架构认识：多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。</p><p>这就是<strong>天然的分布式消息队列</strong>，就是说一个 topic 的数据，是<strong>分散放在多个机器上的，每个机器就放一部分数据</strong>。</p><p>实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性)的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。</p><p>Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。</p><p>Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。然后所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，<strong>要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题</strong>，系统复杂度太高，很容易出问题。Kafka 会均匀的将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。</p><p><img src="/img/mq-9.png" alt="mq-9"></p><p>这么搞，就有所谓的<strong>高可用性</strong>了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的，如果这上面有某个 partition 的 leader，那么此时会<strong>重新选举</strong>一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。</p><p><strong>写数据</strong>的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）</p><p><strong>消费</strong>的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。</p><p>看到这里，相信你大致明白了 Kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 Kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过┭┮﹏┭┮。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Database] Mysql常用命令</title>
      <link href="/database/mysql-commonds.html"/>
      <url>/database/mysql-commonds.html</url>
      
        <content type="html"><![CDATA[<h2 id="1-系统管理"><a href="#1-系统管理" class="headerlink" title="1. 系统管理"></a>1. 系统管理</h2><h3 id="1-1-连接mysql"><a href="#1-1-连接mysql" class="headerlink" title="1.1. 连接mysql"></a>1.1. 连接mysql</h3><p>格式： mysql -h主机地址 -u用户名 －p用户密码</p><p>连接本地：mysql -h<code>localhost/127.0.0.1</code> -u用户名 －p用户密码</p><p>连接远程：mysql -h<code>主机地址</code> -u用户名 －p用户密码<br>退出连接：exit</p><h3 id="1-2-备份数据库"><a href="#1-2-备份数据库" class="headerlink" title="1.2. 备份数据库"></a>1.2. 备份数据库</h3><p><strong>1.导出整个数据库</strong></p><p>导出文件默认是存在mysql\bin目录下</p><p>mysqldump -u 用户名 -p 数据库名 ` 导出的文件名</p><p>mysqldump -u user_name -p123456 database_name ` outfile_name.sql</p><p><strong>2.导出一个表</strong></p><p>mysqldump -u 用户名 -p 数据库名 表名` 导出的文件名</p><p>mysqldump -u user_name -p database_name table_name ` outfile_name.sql</p><p><strong>3.导出一个数据库结构</strong></p><p>mysqldump -u user_name -p -d –add-drop-table database_name ` outfile_name.sql</p><p>-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table</p><p><strong>4.带语言参数导出</strong></p><p>mysqldump -uroot -p –default-character-set=latin1 –set-charset=gbk –skip-opt database_name ` outfile_name.sql</p><p><strong>5、导入数据库</strong></p><p>mysql -u root –p ` [备份文件的保存路径] 或者source [备份文件的保存路径]</p><h3 id="1-3-用户管理"><a href="#1-3-用户管理" class="headerlink" title="1.3. 用户管理"></a>1.3. 用户管理</h3><p><strong>1、创建用户</strong></p><p>​    create user ‘用户名‘@’IP地址’ identified by ‘密码’;</p><p><strong>2、删除用户</strong></p><p>​    drop user ‘用户名‘@’IP地址’;</p><p>​    delete from user where user=’用户名’ and host=’localhost’;</p><p><strong>3、修改用户</strong></p><p>​    rename user ‘用户名‘@’IP地址’; to ‘新用户名‘@’IP地址’;;</p><p><strong>4、修改密码</strong></p><p>​    set password for ‘用户名‘@’IP地址’ = Password(‘新密码’)</p><p>​    mysqladmin -u用户名 -p旧密码 password 新密码</p><h3 id="1-4-权限管理"><a href="#1-4-权限管理" class="headerlink" title="1.4. 权限管理"></a>1.4. 权限管理</h3><h4 id="1-4-1-grant"><a href="#1-4-1-grant" class="headerlink" title="1.4.1. grant"></a>1.4.1. grant</h4><p><strong>1、grant 权限 on 数据库对象 to 用户</strong></p><p>数据库对象的格式为<code>database</code>.<code>table</code>。<code>database</code>.<em>：表示授权数据库对象该数据库的所有表；</em>.*：表示授权数据库对象为所有数据库的所有表。</p><p>grant all privileges on <em>.</em> to <code>user</code>@’<code>ip</code>‘ identified by ‘<code>passwd</code>‘;如果<code>ip</code>为’%’表示不限制IP。</p><p><strong>2、撤销权限</strong>：</p><p>revoke all on <em>.</em> from <code>user</code>@<code>ip</code>; </p><h4 id="1-4-2-普通数据库用户"><a href="#1-4-2-普通数据库用户" class="headerlink" title="1.4.2. 普通数据库用户"></a>1.4.2. 普通数据库用户</h4><p>查询、插入、更新、删除 数据库中所有表数据的权利</p><p>grant select, insert, update, delete on testdb.* to <code>user</code>@’<code>ip</code>‘;</p><h4 id="1-4-3-DBA-用户"><a href="#1-4-3-DBA-用户" class="headerlink" title="1.4.3. DBA 用户"></a>1.4.3. DBA 用户</h4><p><strong>1、授权</strong></p><p>grant all privileges on <em>.</em> to <code>dba</code>@’<code>ip</code>‘ identified by ‘<code>passwd</code>‘;</p><p><strong>2、刷新系统权限</strong></p><p>flush privileges;</p><h4 id="1-4-4-查看用户权限"><a href="#1-4-4-查看用户权限" class="headerlink" title="1.4.4. 查看用户权限"></a>1.4.4. 查看用户权限</h4><p>1、查看当前用户（自己）权限</p><p>show grants;</p><p>2、查看指定MySQL 用户权限</p><p>show grants for <code>user</code>@<code>localhost</code>;</p><p>3、查看user和host</p><p>select user,host from mysql.user order by user;</p><h4 id="1-4-5-权限列表"><a href="#1-4-5-权限列表" class="headerlink" title="1.4.5. 权限列表"></a>1.4.5. 权限列表</h4><p><img src="https://res.cloudinary.com/dqxtn0ick/image/upload/v1510578472/article/database/permission.jpg" alt="img"></p><h4 id="1-4-6-查看主从关系"><a href="#1-4-6-查看主从关系" class="headerlink" title="1.4.6. 查看主从关系"></a>1.4.6. 查看主从关系</h4><p>登录主机：show slave hosts;</p><p>登录从机：show slave status;</p><h2 id="2-数据库操作"><a href="#2-数据库操作" class="headerlink" title="2. 数据库操作"></a>2. 数据库操作</h2><p><strong>1、创建数据库</strong></p><p>create database <code>数据库名</code></p><p><strong>2、显示数据库</strong></p><p>show databases</p><p><strong>3、删除数据</strong></p><p>drop database <code>数据库名</code></p><h2 id="3-数据表操作"><a href="#3-数据表操作" class="headerlink" title="3. 数据表操作"></a>3. 数据表操作</h2><p><strong>1、创建表</strong></p><blockquote><p>create table 表名(</p><p>​    列名  类型  是否可以为空，</p><p>​    列名  类型  是否可以为空</p><p>)ENGINE=InnoDB DEFAULT CHARSET=utf8</p></blockquote><ul><li>默认值，创建列时可以指定默认值，当插入数据时如果未主动设置，则自动添加默认值</li><li>自增，如果为某列设置自增列，插入数据时无需设置此列，默认将自增（表中只能有一个自增列）注意：1、对于自增列，必须是索引（含主键）2、对于自增可以设置步长和起始值</li><li>主键，一种特殊的唯一索引，不允许有空值，如果主键使用单个列，则它的值必须唯一，如果是多列，则其组合必须唯一。</li></ul><p><strong>2、查看表</strong></p><p>show tables;                    # 查看数据库全部表</p><p>select * from 表名;             # 查看表所有内容</p><p><strong>3、删除表</strong></p><p>drop table 表名</p><p><strong>4、清空表内容</strong></p><p>delete from 表名</p><p>truncate table 表名</p><p><strong>5、查看表结构</strong></p><p>desc 表名</p><p><strong>6、修改表</strong></p><blockquote><p>添加列：   alter table 表名 add 列名 类型</p><p>删除列：   alter table 表名 drop column 列名</p><p>修改列：</p><p>​          alter table 表名 modify column 列名 类型;  – 类型</p><p>​          alter table 表名 change 原列名 新列名 类型; – 列名，类型</p><p>添加主键：</p><p>​          alter table 表名 add primary key(列名);</p><p>删除主键：</p><p>​          alter table 表名 drop primary key;</p><p>​          alter table 表名  modify  列名 int, drop primary key;</p><p>添加外键： alter table 从表 add constraint 外键名称（形如：FK_从表_主表） foreign key 从表(外键字段) references 主表(主键字段);</p><p>删除外键： alter table 表名 drop foreign key 外键名称</p><p>修改默认值：ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000;</p><p>删除默认值：ALTER TABLE testalter_tbl ALTER i DROP DEFAULT;</p></blockquote><h2 id="4-表内容操作"><a href="#4-表内容操作" class="headerlink" title="4. 表内容操作"></a>4. 表内容操作</h2><h3 id="4-1-增"><a href="#4-1-增" class="headerlink" title="4.1. 增"></a>4.1. 增</h3><blockquote><p>insert into 表 (列名,列名…) values (值,值,…)</p><p>insert into 表 (列名,列名…) values (值,值,…),(值,值,值…)</p><p>insert into 表 (列名,列名…) select (列名,列名…) from 表</p><p>例：</p><p>​    insert into tab1(name,email) values(‘zhangyanlin’,‘zhangyanlin8851@<a href="http://163.com/" target="_blank" rel="noopener">163.com</a>‘)</p></blockquote><h3 id="4-2-删"><a href="#4-2-删" class="headerlink" title="4.2. 删"></a>4.2. 删</h3><blockquote><p>delete from 表                                      # 删除表里全部数据</p><p>delete from 表 where id＝1 and name＝’zhangyanlin’   # 删除ID =1 和name=’zhangyanlin’ 那一行数据</p></blockquote><h3 id="4-3-改"><a href="#4-3-改" class="headerlink" title="4.3. 改"></a>4.3. 改</h3><blockquote><p>update 表 set name ＝ ‘zhangyanlin’ where id`1</p></blockquote><h3 id="4-4-查"><a href="#4-4-查" class="headerlink" title="4.4. 查"></a>4.4. 查</h3><blockquote><p>select * from 表</p><p>select * from 表 where id ` 1</p><p>select nid,name,gender as gg from 表 where id ` 1</p></blockquote><h3 id="4-5-条件判断"><a href="#4-5-条件判断" class="headerlink" title="4.5. 条件判断"></a>4.5. 条件判断</h3><h4 id="4-5-1-where"><a href="#4-5-1-where" class="headerlink" title="4.5.1. where"></a>4.5.1. where</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> where id <span class="token string">`1 and name!='huwh' and num =12;select * from `</span>table<span class="token string">` where id between 5 and 6;select * from `</span>table<span class="token string">` where id in (11,22,33);select * from `</span>table<span class="token string">` where id not in (11,22,33);select * from `</span>table<span class="token string">` where id in (select nid from `</span>table`<span class="token punctuation">)</span></code></pre><h4 id="4-5-2-通配符like"><a href="#4-5-2-通配符like" class="headerlink" title="4.5.2. 通配符like"></a>4.5.2. 通配符like</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> where name like <span class="token string">'hu%'</span><span class="token punctuation">;</span>   #hu开头<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> where name like <span class="token string">'hu_'</span>    #hu开头后接一个字符</code></pre><h4 id="4-5-3-限制limit"><a href="#4-5-3-限制limit" class="headerlink" title="4.5.3. 限制limit"></a>4.5.3. 限制limit</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> limit <span class="token number">5</span><span class="token punctuation">;</span>   #前<span class="token number">5</span>行<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> limit <span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span>  #从第四行开始的<span class="token number">5</span>行<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> limit <span class="token number">5</span> offset <span class="token number">4</span><span class="token punctuation">;</span>#从第四行开始的<span class="token number">5</span>行</code></pre><h4 id="4-5-4-排序asc，desc"><a href="#4-5-4-排序asc，desc" class="headerlink" title="4.5.4. 排序asc，desc"></a>4.5.4. 排序asc，desc</h4><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> order by 列 asc<span class="token punctuation">;</span>            #跟据“列”从小到大排序（不指定默认为从小到大排序）<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> order by 列 desc<span class="token punctuation">;</span>           #根据“列”从大到小排序<span class="token keyword">select</span> <span class="token operator">*</span> from <span class="token string">`table`</span> order by 列<span class="token number">1</span> desc<span class="token punctuation">,</span>列<span class="token number">2</span> asc<span class="token punctuation">;</span>  #根据“列<span class="token number">1</span>”从大到小排序，如果相同则按“列<span class="token number">2</span>”从小到大排序</code></pre><h4 id="4-5-5-分组group-by"><a href="#4-5-5-分组group-by" class="headerlink" title="4.5.5. 分组group by"></a>4.5.5. 分组group by</h4><p>group by 必须在where之后，order by之前。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">select</span> num<span class="token punctuation">,</span>from <span class="token string">`table`</span> group by num<span class="token punctuation">;</span>     <span class="token keyword">select</span> num<span class="token punctuation">,</span>nid from <span class="token string">`table`</span> group by num<span class="token punctuation">,</span>nid<span class="token punctuation">;</span><span class="token keyword">select</span> num from <span class="token string">`table`</span> where nid <span class="token string">` 10 group by num,nid order nid desc;select num,nid,count(*),sum(score),max(score) from `</span>table<span class="token string">` group by num;select num from `</span>table<span class="token string">` group by num having max(id) `</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">select</span> num from <span class="token string">`table`</span> group by num<span class="token punctuation">;</span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 常用知识点总结</title>
      <link href="/redis/redis-introduce.html"/>
      <url>/redis/redis-introduce.html</url>
      
        <content type="html"><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。</p><p>键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p><p>Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。</p><h2 id="二、数据类型"><a href="#二、数据类型" class="headerlink" title="二、数据类型"></a>二、数据类型</h2><table><thead><tr><th style="text-align:center">数据类型</th><th style="text-align:center">可以存储的值</th><th style="text-align:center">操作</th></tr></thead><tbody><tr><td style="text-align:center">STRING</td><td style="text-align:center">字符串、整数或者浮点数</td><td style="text-align:center">对整个字符串或者字符串的其中一部分执行操作<br> 对整数和浮点数执行自增或者自减操作</td></tr><tr><td style="text-align:center">LIST</td><td style="text-align:center">列表</td><td style="text-align:center">从两端压入或者弹出元素 <br> 对单个或者多个元素<br> 进行修剪，只保留一个范围内的元素</td></tr><tr><td style="text-align:center">SET</td><td style="text-align:center">无序集合</td><td style="text-align:center">添加、获取、移除单个元素<br> 检查一个元素是否存在于集合中<br> 计算交集、并集、差集<br> 从集合里面随机获取元素</td></tr><tr><td style="text-align:center">HASH</td><td style="text-align:center">包含键值对的无序散列表</td><td style="text-align:center">添加、获取、移除单个键值对<br> 获取所有键值对<br> 检查某个键是否存在</td></tr><tr><td style="text-align:center">ZSET</td><td style="text-align:center">有序集合</td><td style="text-align:center">添加、获取、删除元素<br> 根据分值范围或者成员来获取元素<br> 计算一个键的排名</td></tr></tbody></table><blockquote><p><a href="https://redislabs.com/ebook/part-1-getting-started/chapter-1-getting-to-know-redis/1-2-what-redis-data-structures-look-like/" target="_blank" rel="noopener">What Redis data structures look like</a></p></blockquote><h3 id="STRING"><a href="#STRING" class="headerlink" title="STRING"></a>STRING</h3><p><img src="http://img.wanganyu1996.com/redis/redis-string.png" alt="img"></p><pre class=" language-html"><code class="language-html">> set hello worldOK> get hello"world"> del hello(integer) 1> get hello(nil)</code></pre><h3 id="LIST"><a href="#LIST" class="headerlink" title="LIST"></a>LIST</h3><p><img src="http://img.wanganyu1996.com/redis/redis-list.png" alt="img"></p><pre class=" language-html"><code class="language-html">> rpush list-key item(integer) 1> rpush list-key item2(integer) 2> rpush list-key item(integer) 3> lrange list-key 0 -11) "item"2) "item2"3) "item"> lindex list-key 1"item2"> lpop list-key"item"> lrange list-key 0 -11) "item2"2) "item"</code></pre><h3 id="SET"><a href="#SET" class="headerlink" title="SET"></a>SET</h3><p><img src="http://img.wanganyu1996.com/redis/redis-set.png" alt="img"></p><pre class=" language-html"><code class="language-html">> sadd set-key item(integer) 1> sadd set-key item2(integer) 1> sadd set-key item3(integer) 1> sadd set-key item(integer) 0> smembers set-key1) "item"2) "item2"3) "item3"> sismember set-key item4(integer) 0> sismember set-key item(integer) 1> srem set-key item2(integer) 1> srem set-key item2(integer) 0> smembers set-key1) "item"2) "item3"</code></pre><h3 id="HASH"><a href="#HASH" class="headerlink" title="HASH"></a>HASH</h3><p><img src="http://img.wanganyu1996.com/redis/redis-hash.png" alt="img"></p><pre class=" language-html"><code class="language-html">> hset hash-key sub-key1 value1(integer) 1> hset hash-key sub-key2 value2(integer) 1> hset hash-key sub-key1 value1(integer) 0> hgetall hash-key1) "sub-key1"2) "value1"3) "sub-key2"4) "value2"> hdel hash-key sub-key2(integer) 1> hdel hash-key sub-key2(integer) 0> hget hash-key sub-key1"value1"> hgetall hash-key1) "sub-key1"2) "value1"</code></pre><h3 id="ZSET"><a href="#ZSET" class="headerlink" title="ZSET"></a>ZSET</h3><p><img src="http://img.wanganyu1996.com/redis/redis-zset.png" alt="img"></p><pre class=" language-html"><code class="language-html">> zadd zset-key 728 member1(integer) 1> zadd zset-key 982 member0(integer) 1> zadd zset-key 982 member0(integer) 0> zrange zset-key 0 -1 withscores1) "member1"2) "728"3) "member0"4) "982"> zrangebyscore zset-key 0 800 withscores1) "member1"2) "728"> zrem zset-key member1(integer) 1> zrem zset-key member1(integer) 0> zrange zset-key 0 -1 withscores1) "member0"2) "982"</code></pre><h2 id="三、数据结构"><a href="#三、数据结构" class="headerlink" title="三、数据结构"></a>三、数据结构</h2><h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><p>dictht 是一个散列表结构，使用拉链法保存哈希冲突。</p><pre class=" language-c"><code class="language-c"><span class="token comment" spellcheck="true">/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */</span><span class="token keyword">typedef</span> <span class="token keyword">struct</span> dictht <span class="token punctuation">{</span>    dictEntry <span class="token operator">*</span><span class="token operator">*</span>table<span class="token punctuation">;</span>    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> size<span class="token punctuation">;</span>    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> sizemask<span class="token punctuation">;</span>    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> used<span class="token punctuation">;</span><span class="token punctuation">}</span> dictht<span class="token punctuation">;</span></code></pre><pre class=" language-c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> dictEntry <span class="token punctuation">{</span>    <span class="token keyword">void</span> <span class="token operator">*</span>key<span class="token punctuation">;</span>    <span class="token keyword">union</span> <span class="token punctuation">{</span>        <span class="token keyword">void</span> <span class="token operator">*</span>val<span class="token punctuation">;</span>        uint64_t u64<span class="token punctuation">;</span>        int64_t s64<span class="token punctuation">;</span>        <span class="token keyword">double</span> d<span class="token punctuation">;</span>    <span class="token punctuation">}</span> v<span class="token punctuation">;</span>    <span class="token keyword">struct</span> dictEntry <span class="token operator">*</span>next<span class="token punctuation">;</span><span class="token punctuation">}</span> dictEntry<span class="token punctuation">;</span></code></pre><p>Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> dict <span class="token punctuation">{</span>    dictType <span class="token operator">*</span>type<span class="token punctuation">;</span>    <span class="token keyword">void</span> <span class="token operator">*</span>privdata<span class="token punctuation">;</span>    dictht ht<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">long</span> rehashidx<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">/* rehashing not in progress if rehashidx == -1 */</span>    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> iterators<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">/* number of iterators currently running */</span><span class="token punctuation">}</span> dict<span class="token punctuation">;</span></code></pre><p>rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。</p><p>渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。例如在一次 rehash 中，要把 dict[0] rehash 到 dict[1]，这一次会把 dict[0] 上 table[rehashidx] 的键值对 rehash 到 dict[1] 上，dict[0] 的 table[rehashidx] 指向 null，并令 rehashidx++。</p><p>在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。</p><p>采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。</p><pre class=" language-c"><code class="language-c"><span class="token comment" spellcheck="true">/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. */</span><span class="token keyword">int</span> <span class="token function">dictRehash</span><span class="token punctuation">(</span>dict <span class="token operator">*</span>d<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> empty_visits <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">/* Max number of empty buckets to visit. */</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">dictIsRehashing</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>n<span class="token operator">--</span> <span class="token operator">&amp;&amp;</span> d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>used <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        dictEntry <span class="token operator">*</span>de<span class="token punctuation">,</span> <span class="token operator">*</span>nextde<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/* Note that rehashidx can't overflow as we are sure there are more         * elements because ht[0].used != 0 */</span>        <span class="token function">assert</span><span class="token punctuation">(</span>d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size <span class="token operator">></span> <span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">long</span><span class="token punctuation">)</span> d<span class="token operator">-></span>rehashidx<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>table<span class="token punctuation">[</span>d<span class="token operator">-></span>rehashidx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            d<span class="token operator">-></span>rehashidx<span class="token operator">++</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">--</span>empty_visits <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        de <span class="token operator">=</span> d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>table<span class="token punctuation">[</span>d<span class="token operator">-></span>rehashidx<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/* Move all the keys in this bucket from the old to the new hash HT */</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>de<span class="token punctuation">)</span> <span class="token punctuation">{</span>            uint64_t h<span class="token punctuation">;</span>            nextde <span class="token operator">=</span> de<span class="token operator">-></span>next<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">/* Get the index in the new hash table */</span>            h <span class="token operator">=</span> <span class="token function">dictHashKey</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> de<span class="token operator">-></span>key<span class="token punctuation">)</span> <span class="token operator">&amp;</span> d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sizemask<span class="token punctuation">;</span>            de<span class="token operator">-></span>next <span class="token operator">=</span> d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>table<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">;</span>            d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>table<span class="token punctuation">[</span>h<span class="token punctuation">]</span> <span class="token operator">=</span> de<span class="token punctuation">;</span>            d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>used<span class="token operator">--</span><span class="token punctuation">;</span>            d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>used<span class="token operator">++</span><span class="token punctuation">;</span>            de <span class="token operator">=</span> nextde<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>table<span class="token punctuation">[</span>d<span class="token operator">-></span>rehashidx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>        d<span class="token operator">-></span>rehashidx<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/* Check if we already rehashed the whole table... */</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>used <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token function">zfree</span><span class="token punctuation">(</span>d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>table<span class="token punctuation">)</span><span class="token punctuation">;</span>        d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token function">_dictReset</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d<span class="token operator">-></span>ht<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        d<span class="token operator">-></span>rehashidx <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/* More to rehash... */</span>    <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h3 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h3><p>是有序集合的底层实现之一。</p><p>跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。</p><p><a href="http://img.wanganyu1996.com/redis/redis-skipList.png" target="_blank" rel="noopener"><img src="http://img.wanganyu1996.com/redis/redis-skipList.png" alt="img"></a></p><p>在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。</p><p><a href="http://img.wanganyu1996.com/redis/redis-search-skipList.png" target="_blank" rel="noopener"><img src="http://img.wanganyu1996.com/redis/redis-search-skipList.png" alt="img"></a></p><p>与红黑树等平衡树相比，跳跃表具有以下优点：</p><ul><li>插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；</li><li>更容易实现；</li><li>支持无锁操作。</li></ul><h2 id="四、使用场景"><a href="#四、使用场景" class="headerlink" title="四、使用场景"></a>四、使用场景</h2><h3 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h3><p>可以对 String 进行自增自减运算，从而实现计数器功能。</p><p>Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。</p><h3 id="查找表"><a href="#查找表" class="headerlink" title="查找表"></a>查找表</h3><p>例如 DNS 记录就很适合使用 Redis 进行存储。</p><p>查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。</p><h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>List 是一个双向链表，可以通过 lpop 和 lpush 写入和读取消息。</p><p>不过最好使用 Kafka、RabbitMQ 等消息中间件。</p><h3 id="会话缓存"><a href="#会话缓存" class="headerlink" title="会话缓存"></a>会话缓存</h3><p>可以使用 Redis 来统一存储多台应用服务器的会话信息。</p><p>当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。</p><h3 id="分布式锁实现"><a href="#分布式锁实现" class="headerlink" title="分布式锁实现"></a>分布式锁实现</h3><p>在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。</p><p>可以使用 Reids 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。</p><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。</p><p>ZSet 可以实现有序性操作，从而实现排行榜等功能。</p><h2 id="五、Redis-与-Memcached"><a href="#五、Redis-与-Memcached" class="headerlink" title="五、Redis 与 Memcached"></a>五、Redis 与 Memcached</h2><p>两者都是非关系型内存键值数据库，主要有以下不同：</p><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。</p><h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><p>Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。</p><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。</p><p>Redis Cluster 实现了分布式的支持。</p><h3 id="内存管理机制"><a href="#内存管理机制" class="headerlink" title="内存管理机制"></a>内存管理机制</h3><ul><li><p>在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。</p></li><li><p>Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。</p></li></ul><h2 id="六、键的过期时间"><a href="#六、键的过期时间" class="headerlink" title="六、键的过期时间"></a>六、键的过期时间</h2><p>Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。</p><p>对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。</p><h2 id="七、数据淘汰策略"><a href="#七、数据淘汰策略" class="headerlink" title="七、数据淘汰策略"></a>七、数据淘汰策略</h2><p>可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。</p><p>Reids 具体有 6 种淘汰策略：</p><table><thead><tr><th style="text-align:center">策略</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">volatile-lru</td><td style="text-align:center">从已设置过期时间的数据集中挑选最近最少使用的数据淘汰</td></tr><tr><td style="text-align:center">volatile-ttl</td><td style="text-align:center">从已设置过期时间的数据集中挑选将要过期的数据淘汰</td></tr><tr><td style="text-align:center">volatile-random</td><td style="text-align:center">从已设置过期时间的数据集中任意选择数据淘汰</td></tr><tr><td style="text-align:center">allkeys-lru</td><td style="text-align:center">从所有数据集中挑选最近最少使用的数据淘汰</td></tr><tr><td style="text-align:center">allkeys-random</td><td style="text-align:center">从所有数据集中任意选择数据进行淘汰</td></tr><tr><td style="text-align:center">noeviction</td><td style="text-align:center">禁止驱逐数据</td></tr></tbody></table><p>作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。</p><p>使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。</p><p>Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。</p><h2 id="八、持久化"><a href="#八、持久化" class="headerlink" title="八、持久化"></a>八、持久化</h2><p>Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。</p><h3 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h3><p>将某个时间点的所有数据都存放到硬盘上。</p><p>可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。</p><p>如果系统发生故障，将会丢失最后一次创建快照之后的数据。</p><p>如果数据量很大，保存快照的时间会很长。</p><h3 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h3><p>将写命令添加到 AOF 文件（Append Only File）的末尾。</p><p>使用 AOF 持久化需要设置同步选项，从而确保写命令什么时候会同步到磁盘文件上。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">同步频率</th></tr></thead><tbody><tr><td style="text-align:center">always</td><td style="text-align:center">每个写命令都同步</td></tr><tr><td style="text-align:center">everysec</td><td style="text-align:center">每秒同步一次</td></tr><tr><td style="text-align:center">no</td><td style="text-align:center">让操作系统来决定何时同步</td></tr></tbody></table><ul><li>always 选项会严重减低服务器的性能；</li><li>everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；</li><li>no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。</li></ul><p>随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。</p><h2 id="九、事务"><a href="#九、事务" class="headerlink" title="九、事务"></a>九、事务</h2><p>一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。</p><p>事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。</p><p>Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。</p><h2 id="十、事件"><a href="#十、事件" class="headerlink" title="十、事件"></a>十、事件</h2><p>Redis 服务器是一个事件驱动程序。</p><h3 id="文件事件"><a href="#文件事件" class="headerlink" title="文件事件"></a>文件事件</h3><p>服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。</p><p>Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。</p><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/9ea86eb5-000a-4281-b948-7b567bd6f1d8.png" target="_blank" rel="noopener"><img src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/9ea86eb5-000a-4281-b948-7b567bd6f1d8.png" alt="img"></a></p><h3 id="时间事件"><a href="#时间事件" class="headerlink" title="时间事件"></a>时间事件</h3><p>服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。</p><p>时间事件又分为：</p><ul><li>定时事件：是让一段程序在指定的时间之内执行一次；</li><li>周期性事件：是让一段程序每隔指定时间就执行一次。</li></ul><p>Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。</p><h3 id="事件的调度与执行"><a href="#事件的调度与执行" class="headerlink" title="事件的调度与执行"></a>事件的调度与执行</h3><p>服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。</p><p>事件调度与执行由 aeProcessEvents 函数负责，伪代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">aeProcessEvents</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 获取到达时间离当前时间最接近的时间事件</span>    time_event <span class="token operator">=</span> aeSearchNearestTimer<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 计算最接近的时间事件距离到达还有多少毫秒</span>    remaind_ms <span class="token operator">=</span> time_event<span class="token punctuation">.</span>when <span class="token operator">-</span> unix_ts_now<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0</span>    <span class="token keyword">if</span> remaind_ms <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>        remaind_ms <span class="token operator">=</span> <span class="token number">0</span>    <span class="token comment" spellcheck="true"># 根据 remaind_ms 的值，创建 timeval</span>    timeval <span class="token operator">=</span> create_timeval_with_ms<span class="token punctuation">(</span>remaind_ms<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定</span>    aeApiPoll<span class="token punctuation">(</span>timeval<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 处理所有已产生的文件事件</span>    procesFileEvents<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 处理所有已到达的时间事件</span>    processTimeEvents<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 初始化服务器</span>    init_server<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 一直处理事件，直到服务器关闭为止</span>    <span class="token keyword">while</span> server_is_not_shutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        aeProcessEvents<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 服务器关闭，执行清理操作</span>    clean_server<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>从事件处理的角度来看，服务器运行流程如下：</p><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/c0a9fa91-da2e-4892-8c9f-80206a6f7047.png" target="_blank" rel="noopener"><img src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/c0a9fa91-da2e-4892-8c9f-80206a6f7047.png" alt="img"></a></p><h2 id="十一、复制"><a href="#十一、复制" class="headerlink" title="十一、复制"></a>十一、复制</h2><p>通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。</p><p>一个从服务器只能有一个主服务器，并且不支持主主复制。</p><h3 id="连接过程"><a href="#连接过程" class="headerlink" title="连接过程"></a>连接过程</h3><ol><li><p>主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；</p></li><li><p>从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；</p></li><li><p>主服务器每执行一次写命令，就向从服务器发送相同的写命令。</p></li></ol><h3 id="主从链"><a href="#主从链" class="headerlink" title="主从链"></a>主从链</h3><p>随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。</p><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/395a9e83-b1a1-4a1d-b170-d081e7bb5bab.png" target="_blank" rel="noopener"><img src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/395a9e83-b1a1-4a1d-b170-d081e7bb5bab.png" alt="img"></a></p><h2 id="十二、Sentinel"><a href="#十二、Sentinel" class="headerlink" title="十二、Sentinel"></a>十二、Sentinel</h2><p>Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。</p><h2 id="十三、分片"><a href="#十三、分片" class="headerlink" title="十三、分片"></a>十三、分片</h2><p>分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。</p><p>假设有 4 个 Reids 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，… ，有不同的方式来选择一个指定的键存储在哪个实例中。</p><ul><li>最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。</li><li>还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。</li></ul><p>根据执行分片的位置，可以分为三种分片方式：</p><ul><li>客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。</li><li>代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。</li><li>服务器分片：Redis Cluster。</li></ul><h2 id="十四、一个简单的论坛系统分析"><a href="#十四、一个简单的论坛系统分析" class="headerlink" title="十四、一个简单的论坛系统分析"></a>十四、一个简单的论坛系统分析</h2><p>该论坛系统功能如下：</p><ul><li>可以发布文章；</li><li>可以对文章进行点赞；</li><li>在首页可以按文章的发布时间或者文章的点赞数进行排序显示。</li></ul><h3 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h3><p>文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。</p><p>Redis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。</p><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/7c54de21-e2ff-402e-bc42-4037de1c1592.png" target="_blank" rel="noopener"><img src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/7c54de21-e2ff-402e-bc42-4037de1c1592.png" alt="img"></a></p><h3 id="点赞功能"><a href="#点赞功能" class="headerlink" title="点赞功能"></a>点赞功能</h3><p>当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。</p><p>为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。</p><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/485fdf34-ccf8-4185-97c6-17374ee719a0.png" target="_blank" rel="noopener"><img src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/485fdf34-ccf8-4185-97c6-17374ee719a0.png" alt="img"></a></p><h3 id="对文章进行排序"><a href="#对文章进行排序" class="headerlink" title="对文章进行排序"></a>对文章进行排序</h3><p>为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）</p><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/f7d170a3-e446-4a64-ac2d-cb95028f81a8.png" target="_blank" rel="noopener"><img src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/f7d170a3-e446-4a64-ac2d-cb95028f81a8.png" alt="img"></a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>Carlson J L. Redis in Action[J]. Media.johnwiley.com.au, 2013.</li><li><a href="http://redisbook.com/index.html" target="_blank" rel="noopener">黄健宏. Redis 设计与实现 [M]. 机械工业出版社, 2014.</a></li><li><a href="https://redislabs.com/ebook/foreword/" target="_blank" rel="noopener">REDIS IN ACTION</a></li><li><a href="http://ticki.github.io/blog/skip-lists-done-right/" target="_blank" rel="noopener">Skip Lists: Done Right</a></li><li><a href="http://www.cnblogs.com/loveincode/p/7411911.html" target="_blank" rel="noopener">论述 Redis 和 Memcached 的差异</a></li><li><a href="http://wiki.jikexueyuan.com/project/redis-guide" target="_blank" rel="noopener">Redis 3.0 中文版- 分片</a></li><li><a href="http://www.scienjus.com/redis-use-case/" target="_blank" rel="noopener">Redis 应用场景</a></li><li><a href="https://redis.io/topics/lru-cache" target="_blank" rel="noopener">Using Redis as an LRU cache</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
